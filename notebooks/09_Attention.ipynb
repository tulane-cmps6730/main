{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Tulane](https://github.com/tulane-cmps6730/main/blob/main/img/banner.png?raw=true)\n",
        "\n",
        "<center>\n",
        "\n",
        "<font size=\"+3\">Attention</font>\n",
        "\n",
        "[Aron Culotta](https://cs.tulane.edu/~aculotta/)  \n",
        "[Tulane University](https://cs.tulane.edu/)\n",
        "\n",
        "<a href=\"http://colab.research.google.com/github/tulane-cmps6730/main/blob/main/notebooks/09_Attention.ipynb\">\n",
        "        <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Google_Colaboratory_SVG_Logo.svg/320px-Google_Colaboratory_SVG_Logo.svg.png\"  width=10%/></a>\n",
        "<a href=\"https://github.com/tulane-cmps6730/main/tree/main\">\n",
        "        <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/GitHub_Invertocat_Logo.svg/240px-GitHub_Invertocat_Logo.svg.png\" width=6%/></a>\n",
        "\n",
        "In this module, we'll learn about attention mechanisms to better capture long-distance relationships in language sequences.\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "u7t32OQMvRZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Motivation"
      ],
      "metadata": {
        "id": "f8OiXeEVwfGw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04LxYCDQvHc8"
      },
      "source": [
        "### LSTMs as language models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> While the acting was pretty good, overall the movie was quite bad.\n",
        "\n",
        "![figs/lstmclf1.png](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/lstmclf1.png?raw=1)\n",
        "\n",
        "\n",
        "Each hidden state is now a **context-dependent** word representation.\n",
        "\n",
        "<br><br><br><br>\n",
        "\n"
      ],
      "metadata": {
        "id": "_wYMuHKrw6iX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bidirectional LSTMs"
      ],
      "metadata": {
        "id": "jO4DP-kjwwFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's no reason to limit ourselves to left-to-right ordering:\n",
        "\n",
        "![figs/lstmclf2.png](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/lstmclf2.png?raw=1)\n",
        "\n",
        "Word representation is now the concatenation of hidden vectors from both directions.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ctDXLahQwssF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTMs for Classification"
      ],
      "metadata": {
        "id": "14jFC71cwyqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![figs/lstmclf3.png](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/lstmclf3.png?raw=1)\n",
        "\n",
        "What are our options here?\n",
        "\n",
        "\n",
        "<br><br><br><br>\n",
        "\n",
        "**concatenate**: $h_1 \\oplus h_2 \\oplus \\ldots \\oplus h_n$\n",
        "\n",
        "What's wrong with this?\n",
        "\n",
        "\n",
        "<br><br><br><br>\n",
        "\n",
        "average: $\\frac{1}{n}\\sum_i^n h_i$\n",
        "\n",
        "What's wrong with this?\n",
        "\n",
        "<br><br><br><br>\n",
        "\n",
        "$h_{\\hbox{bad}}$ contributes as much to the average as $h_{\\hbox{the}}$!\n",
        "\n",
        "<br><br>\n",
        "\n",
        "How can we get something like a weighted average?\n",
        "\n",
        "$\\frac{\\sum_i^n w_i h_i}{\\sum_i^n w_i}$\n",
        "\n",
        "<br><br><br>\n",
        "We need a way to\n",
        "\n",
        "- get a fixed representation from an arbitrary list of values\n",
        "- have the representation weighted by the importance of each input value"
      ],
      "metadata": {
        "id": "Lh6cwOZJwuhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Attention\n"
      ],
      "metadata": {
        "id": "kapVP3M5xCIZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEb4XthLvHc8"
      },
      "source": [
        "\n",
        "> Given a set of vector **values**, and a vector **query**,  \n",
        "> **attention** is a technique to compute a weighted sum of the values, dependent on the query.\n",
        "\n",
        "- a selective summary of the values based on the query\n",
        "- gives a fixed-size representation of the values\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overall approach\n"
      ],
      "metadata": {
        "id": "bnX9QdcvxEa5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwkgFJPUvHc9"
      },
      "source": [
        "\n",
        "**Input**: sequence of value vectors $\\mathbf{h}_1 \\ldots \\mathbf{h}_n \\in \\mathbb{R}^{d_h}$ and a query vector $\\mathbf{q} \\in \\mathbb{R}^{d_q}$\n",
        "\n",
        "1. Compute **attention scores** $\\mathbf{s} \\in \\mathbb{R}^n$\n",
        "  - we'll see how in a moment\n",
        "\n",
        "\n",
        "2. Apply softmax to get the **attention distribution** $\\alpha$:\n",
        "  - $\\alpha = \\mathrm{softmax}(\\mathbf{s}) \\in \\mathbb{R}^n$\n",
        "  \n",
        "  \n",
        "3. Compute the **attention output**, the sum of values weighted by attention distribution:\n",
        "  - $\\mathbf{a} = \\sum_i^n \\alpha_i \\mathbf{h}_i \\in \\mathbb{R}^{d_h}$\n",
        "  - $\\mathbf{a}$ then becomes input features for classification layer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Types of attention\n"
      ],
      "metadata": {
        "id": "ixyhlyh1xISE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGVdkp1LvHc9"
      },
      "source": [
        "\n",
        "\n",
        "The attention scores should somehow combine the query vector with the value vectors to score the importance of each value. Common choices include:\n",
        "\n",
        "- **Dot product:** $~~~\\mathbf{s}_i = \\mathbf{q} \\cdot \\mathbf{h}_i \\in \\mathbb{R}$\n",
        "  - this assumes $d_h == d_q$\n",
        "\n",
        "\n",
        "- **Multiplicative attention:**   $~~~\\mathbf{s}_i = \\mathbf{q}^T \\mathbf{W} \\mathbf{h}_i \\in \\mathbb{R}$\n",
        "  - must learn the matrix $W \\in \\mathbb{R}^{d_q \\times d_h}$\n",
        "  - c.f., [`torch.nn.Bilinear`](https://pytorch.org/docs/stable/generated/torch.nn.Bilinear.html)\n",
        "  \n",
        "\n",
        "- **Additive attention:**   $~~~\\mathbf{s}_i = \\mathbf{v}^T \\mathrm{tanh}(\\mathbf{W_1} \\mathbf{h}_i  + \\mathbf{W_2}\\mathbf{q}) \\in \\mathbb{R}$\n",
        "  - must learn vector $\\mathbf{v} \\in \\mathbb{R}^{d_v}$ and the matrices $W_1 \\in \\mathbb{R}^{d_v \\times d_h}$, $W_2 \\in \\mathbb{R}^{d_v \\times d_q}$,=\n",
        "  - must select **attention dimensionality** $d_v$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Learning the query vector\n"
      ],
      "metadata": {
        "id": "-CO_vzVSxM5T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U5eWZbfvHc9"
      },
      "source": [
        "\n",
        "\n",
        "But wait, we don't know what $\\mathbf{q}$ should be!\n",
        "\n",
        "We'll have to learn it.\n",
        "\n",
        "$\\mathbf{s_i} = \\mathrm{tanh}(W_s \\cdot \\mathbf{h}_i) \\in \\mathbb{R}~~~~~~~~~ W_s \\in \\mathbb{R^{d_h}}$\n",
        "\n",
        "$\\alpha = \\mathrm{softmax}({\\mathbf{s}})$\n",
        "\n",
        "$\\mathbf{a} = \\sum_i^n \\alpha_i \\mathbf{h}_i \\in \\mathbb{R}^{d_h}$\n",
        "\n",
        "$y = \\mathrm{softmax}(W_y \\cdot \\mathbf{a})$\n",
        "<br><br>\n",
        "\n",
        "\n",
        "![figs/lstmclf4.png](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/lstmclf4.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Attention for Language Models"
      ],
      "metadata": {
        "id": "ioD31_UvxUbm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnX9hjiXvHc9"
      },
      "source": [
        "\n",
        "\n",
        "- LSTMs go through a lot of trouble to enable long-range dependencies\n",
        "\n",
        "- What if we just let every word in a sentence influence every other word ?!\n",
        "\n",
        "\n",
        "![figs/selfatt1.png](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/selfatt1.png?raw=1)\n",
        "\n",
        "We can use attention to determine which other words are important to predict the next word $t$.\n",
        "\n",
        "$$h_t =  \\sum_{i\\ne t}^n \\alpha_i \\mathbf{h}_i$$\n",
        "\n",
        "\n",
        "Is this scalable?\n",
        "\n",
        "<br><br>\n",
        "\n",
        "\n",
        "By removing sequential dependencies, we can compute embeddings in parallel for each sentence.\n",
        "- In complexity speak, we've increased the Work but decreased the Span, so it is more parallelizable\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention-based word representations"
      ],
      "metadata": {
        "id": "nF36atMHxfZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "By applying attention to each token in the input, we compute hidden representations $h_i$ for each input work.\n",
        "- Each $h_i$ depends on all the other words in the input.\n",
        "\n",
        "\n",
        "$$\\mathbf{v}_j = V\\mathbf{x_j} ~~~V\\in \\mathbb{R}^{dxd} ~~~$$ **values for node j**\n",
        "\n",
        "$$\\mathbf{k}_j = K \\mathbf{x}_j ~~~K\\in \\mathbb{R}^{dxd} ~~~$$ **keys for node j**\n",
        "\n",
        "$$\\mathbf{q}_i = Q\\mathbf{x_i}~~~$$ **query for node i**\n",
        "\n",
        "$$\\alpha_{ij} = \\frac{\\exp(\\mathbf{q}_i \\cdot \\mathbf{k}_j)}{\\sum_{j'} \\exp({\\mathbf{q}_i \\cdot \\mathbf{k}_{j'})}} ~~~$$ **affinities between node i and j**\n",
        "\n",
        "$$\\mathbf{h}_i = \\sum_{j=1}^n \\alpha_{ij} \\mathbf{v}_j$$\n",
        "\n",
        "\n",
        "$\\mathbf{h}_i$ is the contextual representation of input $\\mathbf{x}_i$.  $\\alpha_{ij}$ controls the strength of each contribution from $v_j$.\n",
        "\n",
        "<br>\n",
        "\n",
        "This tells us **what information from what other tokens, should be used in representing** $\\mathbf{x}_i$.\n",
        "\n",
        "\n",
        "The matrices $K$, $Q$, $V$ allow us to use different views of each $\\mathbf{x}_i$ for the different roles of key, query, and value.\n",
        "\n",
        "<br>\n",
        "\n",
        "<br><br><br>\n",
        "\n",
        "<img src=\"https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/selfattention.png?raw=1\" width=60%/>\n",
        "\n",
        "[source](https://web.stanford.edu/class/cs224n/readings/cs224n-self-attention-transformers-2023_draft.pdf)\n",
        "\n"
      ],
      "metadata": {
        "id": "PqtqWcopxcLM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Position"
      ],
      "metadata": {
        "id": "zygxcHKayDIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "But wait, the above approach completely ignores word order!!\n",
        "\n",
        "<br><br><br>\n",
        "\n",
        "**Idea**: explicitly add the position of a word in its representation.\n",
        "\n",
        "- E.g., we can represent a binary string $p$ encoding the position of a word; e.g. $000, 001, 010, 011,... 111$ for sequences up to length 8.\n",
        "\n",
        "\n",
        "- Then, we can represent each input embedding $h_i$ as the concatenation $h_i \\oplus p_i$ or alternatively as the sum $h_i + p_i$.\n",
        "\n",
        "\n",
        "- We can also get more fancy and learn an embedding for $p_i$.\n",
        "  - requires picking a maximum sentence length\n",
        "  - most common approach\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8couM3aMyBFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Simple attention example"
      ],
      "metadata": {
        "id": "5S24YoMLzJXl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tXyJIH8vHc-"
      },
      "source": [
        "\n",
        "\n",
        "Let's walk through a simple example of an attention model for binary classification.\n",
        "\n",
        "We'll assume there are three words in the world: $a,b,c$. We will assume that $a$ and $b$ matter for the classification, but $c$ doesn't.\n",
        "\n",
        "We want to see if the attention weights will \"pay attention to\" $a$ and $b$ and not $c$.\n",
        "\n",
        "\n",
        "Below is a simple implementation of attention where we assume:\n",
        "- There is no embedding layer; so, we just use the `x` input vectors directly instead of `h`.\n",
        "- We are doing binary classification, so we use Sigmoid instead of Softmax.\n",
        "\n",
        "This would represent a problem where we want to classify a document into one of two classes, using the raw one-hot encoding of each word as input.\n",
        "\n",
        "$\\mathbf{s_i} = \\mathrm{tanh}(W_s \\cdot \\mathbf{x}_i) \\in \\mathbb{R}~~~~~~~~~ W_s \\in \\mathbb{R^{d_x}}$\n",
        "\n",
        "$\\alpha = \\mathrm{softmax}({\\mathbf{s}})$\n",
        "\n",
        "$\\mathbf{a} = \\sum_i^n \\alpha_i \\mathbf{x}_i \\in \\mathbb{R}^{d_x}$\n",
        "\n",
        "$ y = \\mathrm{sigmoid}(W_y \\cdot \\mathbf{a}) $\n",
        "\n",
        "<img src=\"https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/lstmclf4.png?raw=1\" width=\"40%\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qs5taqB7vHc-"
      },
      "outputs": [],
      "source": [
        "# Let's package these computations up inside of an nn.Module so we can learn W_s and W_y.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleAttention(nn.Module):\n",
        "    def __init__(self, input_size, verbose=False):\n",
        "        super(SimpleAttention, self).__init__()\n",
        "        # Since we don't know what the output size will be (the number of tokens), we can't use nn.Linear:\n",
        "        # self.input_to_attention = nn.Linear(input_size, output_size=??, bias=False)\n",
        "        # Instead, we'll just use the Parameter object, which is a trainable tensor.\n",
        "        self.W_s = nn.Parameter(torch.randn(input_size, dtype=torch.float64))\n",
        "\n",
        "        # W_y: hidden to prediction\n",
        "        self.W_y = nn.Linear(input_size, 1, bias=False, dtype=torch.float64)\n",
        "\n",
        "        self.verbose = verbose\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax(dim=0)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # \"@\" is the matrix multiply operator\n",
        "        # This computes s = tanh(x * W_s) for all tokens at the same time.\n",
        "        s = self.tanh(x @ self.W_s)\n",
        "        # normalize using softmax\n",
        "        alpha = self.softmax(s)\n",
        "        # compute final combined embeddings\n",
        "        a = alpha @ x\n",
        "        # classify\n",
        "        y = self.sigmoid(self.W_y(a))\n",
        "        if self.verbose:\n",
        "            print('s=\\n', s)\n",
        "            print('alpha=\\n', alpha)\n",
        "            print('a=\\n', a)\n",
        "            print('y=\\n', y)\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ8ONzyFvHc_"
      },
      "source": [
        "Let's make some fake data where the input vocabulary `['a', 'b', 'c']`. Generate data such that:\n",
        "- Documents with `a` are likely to be positive.\n",
        "- Documents with `b` are likely to be negative.\n",
        "- Documents with `c` are equally likely to be positive or negative.\n",
        "\n",
        "So, we would expect our attention layer to pay attention to words `a` and `b` but ignore `c`.\n",
        "\n",
        "And, we expect the classification layer to have large positive weights for `a` and large negative weights for `b`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Q2a5yEAWvHc_",
        "outputId": "4352b5f0-bbe0-4b1e-b8e4-425c1e53b822",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [0., 0., 1.],\n",
              "        [1., 0., 0.],\n",
              "        [0., 0., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# 1-hot encodings of the \"words\" a,b,c\n",
        "a = [1,0,0]\n",
        "b = [0,1,0]\n",
        "c = [0,0,1]\n",
        "\n",
        "# e.g., the document containing a, c, a, c\n",
        "torch.tensor([a,c,a,c], dtype=torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "weCXEj9QvHc_",
        "outputId": "2b561d5d-5340-4a68-8392-b2555584a025",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s=\n",
            " tensor([ 0.9290, -0.4267,  0.9290, -0.4267], dtype=torch.float64,\n",
            "       grad_fn=<TanhBackward0>)\n",
            "alpha=\n",
            " tensor([0.3975, 0.1025, 0.3975, 0.1025], dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "a=\n",
            " tensor([0.7951, 0.0000, 0.2049], dtype=torch.float64,\n",
            "       grad_fn=<SqueezeBackward4>)\n",
            "y=\n",
            " tensor([0.4501], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4501], dtype=torch.float64, grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model = SimpleAttention(input_size=3, verbose=True)\n",
        "model(torch.tensor([a,c,a,c], dtype=torch.float64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eVoJJZs_vHc_",
        "outputId": "9febfc62-06cb-4574-86cb-15c91524d659",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 0., 0.],\n",
            "         [0., 0., 1.],\n",
            "         [1., 0., 0.],\n",
            "         [0., 0., 1.]]], dtype=torch.float64)\n",
            "tensor(1., dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# create training instances where\n",
        "# a -> label=1\n",
        "# b -> label=0\n",
        "# c -> label=random\n",
        "X = []\n",
        "y = []\n",
        "for _ in range(10):\n",
        "    X.append(torch.tensor([a,c,a,c], dtype=torch.float64))\n",
        "    y.append(1)\n",
        "\n",
        "for _ in range(10):\n",
        "    X.append(torch.tensor([b,c,b,c], dtype=torch.float64))\n",
        "    y.append(0)\n",
        "X = torch.stack(X)\n",
        "# print first training instance\n",
        "print(X[:1])\n",
        "y = torch.tensor(y, dtype=torch.float64)\n",
        "# print first label\n",
        "print(y[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4GTwVXykvHc_"
      },
      "outputs": [],
      "source": [
        "data = list(zip(X,y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UGrPWF2CvHc_",
        "outputId": "dea537e4-6e47-48fe-8cad-dbde7091ea70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 49.01it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBCElEQVR4nO3deXwU9f3H8fcmIQlXEjCahCQQQUVQ5CYNGkVNBUWORhRRC1KrraJCU1vFVhCtBBUtHhSRFs+fiEc4WhSRCIqKYglYRIpguUnCYUkgIIHN/P74dgOBHLvJ7k529/V8POaRyex3Zz+TMebNfL/zHYdlWZYAAACCRJjdBQAAAHgT4QYAAAQVwg0AAAgqhBsAABBUCDcAACCoEG4AAEBQIdwAAICgEmF3Af5WUVGh3bt3q2XLlnI4HHaXAwAA3GBZlg4ePKg2bdooLKz2azMhF252796t1NRUu8sAAAD1sGPHDqWkpNTaJuTCTcuWLSWZH05MTIzN1QAAAHeUlpYqNTW18u94bUIu3Li6omJiYgg3AAAEGHeGlDCgGAAABBXCDQAACCqEGwAAEFQINwAAIKgQbgAAQFAh3AAAgKBCuAEAAEGFcAMAAIIK4QYAAASVkJuh2FecTmnFCqmwUEpKkjIzpfBwu6sCACD0EG68IC9PGjtW2rnzxLaUFOmZZ6TsbPvqAgAgFNEt1UB5edKwYVWDjSTt2mW25+XZUxcAAKGKcNMATqe5YmNZp7/m2jZunGkHAAD8g3DTACtWnH7F5mSWJe3YIX38sf9qAgAg1DHmpgEKC91rd+21UkaG1KfPiSU52bPPYsAyAADuIdw0QFKSe+2OHJE++sgsJ7/35LDTq5cUF1f9+xmwDACA+xyWVd2IkeBVWlqq2NhYlZSUKCYmpkH7cjqltDQzeLi6n6LDYa7QLFworV4trVpllm++qX4cTseOVQNP167SokVmYPKp+3c4zNd33iHgAACCnyd/vwk3DeS6W0qqGkBqCx9lZdKaNdJXX50IPP/5z+n7jogw+zl2rPrPdjjMFZwtW+iiAgAEN8JNLbwdbqTqu41SU6Vp09y/qrJvX9Wws2qV2eaOZcukfv08rRoAgMDhyd9vxtx4QXa2NGRIwwb8xsdLV19tFslcBXr2WXMreV3cHdgMAEAoINx4SXi4d6+eOBxmzI073B3YDABAKGCem0YsM9OMqXGN3zmVw2G6vzIz/VsXAACNGeGmEQsPN7d7SzUHnGnTGEwMAMDJCDeNXHa2uePq1En/oqK4DRwAgOoQbgJAdra0dau5K+qZZ6SwMOnoUalDB7srAwCg8SHcBAjXgOV775Wuv95s+/OfbS0JAIBGiXATgHJyzNc33uA2cAAATkW4CUB9+kgXX2xmLv7LX+yuBgCAxoVwE6BcV29mzJAOH7a3FgAAGhPCTYAaMkQ6+2xp/37ptdfsrgYAgMaDcBOgwsPN86wkM7C4osLeegAAaCwINwHsF7+QYmKkjRul99+3uxoAABoHwk0Aa9lSuuMOs/700/bWAgBAY0G4CXD33GO6qD76SFq71u5qAACwH+EmwLVty6R+AACcjHATBH7zG/N1zhxp9257awEAwG6EmyDQp490ySVmUr/p0+2uBgAAexFugoRrUr8XXpDKyuytBQAAOxFugsTgwVL79tIPP0ivvmp3NQAA2IdwEyTCw6Vx48w6k/oBAEIZ4SaIjB4txcZKmzZJixbZXQ0AAPYg3ASRFi2kX/3KrHNbOAAgVBFugsw990gREdKyZdKaNXZXAwCA/xFugkxKinTDDWadqzcAgFBEuAlCJ0/qt2uXvbUAAOBvhJsg1KuXdOml0vHjTOoHAAg9hJsgxaR+AIBQRbgJUtdeK3XoIP33v9Irr9hdDQAA/kO4CVJM6gcACFWEmyB2661SXJy0ebP0j3/YXQ0AAP5BuAliJ0/q9/TT9tYCAIC/EG6C3N13m0n9Pv5YWr3a7moAAPC9RhFupk+frrS0NEVHRys9PV2rVq2qse3LL78sh8NRZYmOjvZjtYElJUUaPtysM6kfACAU2B5u5s6dq5ycHE2cOFEFBQXq2rWr+vfvrz179tT4npiYGBUWFlYu27Zt82PFgcc1qd/cudLOnfbWAgCAr9kebp5++mndfvvtGj16tDp37qwXXnhBzZo10+zZs2t8j8PhUGJiYuWSkJBQY9ujR4+qtLS0yhJqevaULrvMTOr3/PN2VwMAgG/ZGm7Ky8u1evVqZWVlVW4LCwtTVlaWVq5cWeP7Dh06pHbt2ik1NVVDhgzR+vXra2ybm5ur2NjYyiU1NdWrxxAoXJP6zZwpHTpkby0AAPiSreFm3759cjqdp115SUhIUFFRUbXv6dixo2bPnq0FCxbo9ddfV0VFhfr27audNfS3jB8/XiUlJZXLjh07vH4cgeDaa6VzzpEOHGBSPwBAcLO9W8pTGRkZGjlypLp166bLLrtMeXl5OvPMMzVz5sxq20dFRSkmJqbKEorCwk6MvZk2TXI6bS0HAACfsTXcxMfHKzw8XMXFxVW2FxcXKzEx0a19NGnSRN27d9fmzZt9UWJQGTVKatWKSf0AAMHN1nATGRmpnj17Kj8/v3JbRUWF8vPzlZGR4dY+nE6n1q1bp6SkJF+VGTSaN5d+/WuzzqR+AIBgZXu3VE5OjmbNmqVXXnlFGzZs0J133qmysjKNHj1akjRy5EiNHz++sv0jjzyiJUuW6D//+Y8KCgp0yy23aNu2bfrlL39p1yEElLvvlpo0kT75RPrnP+2uBgAA74uwu4Dhw4dr7969mjBhgoqKitStWzctXry4cpDx9u3bFRZ2IoP997//1e23366ioiK1atVKPXv21Oeff67OnTvbdQgBpU0b6cYbpddeM5P6/d//2V0RAADe5bAsy7K7CH8qLS1VbGysSkpKQnZw8Zo1Uo8e5rEM//mPFKJ3xwMAAognf79t75aC/3XvLl1+OZP6AQCCE+EmRLluC2dSPwBAsCHchKiBA6Vzz5VKSqSXXrK7GgAAvIdwE6KY1A8AEKwINyFs5EipdWszqHjyZGnOHGn5coIOACCwEW5CWPPmUr9+Zn3CBOmmm8xA47Q0KS/PzsoAAKg/wk0Iy8uT5s07ffuuXdKwYQQcAEBgItyEKKdTGjtWqm6WI9e2cePoogIABB7CTYhasULaubPm1y1L2rHDtAMAIJAQbkJUYaF32wEA0FgQbkKUuw9R52HrAIBAQ7gJUZmZUkqK5HBU/7rDYZ45lZnp37oAAGgowk2ICg+XnnnGrNcUcKZNM+0AAAgkhJsQlp0tvfOOlJxcdXtUlNmenW1PXQAANAThJsRlZ0tbt0rLlklPPWW2HT8uXXGFrWUBAFBvhBsoPNzMVJyTI3XubOa2WbTI7qoAAKgfwg2q+NnPzNfqZi4GACAQEG5QhSvcvP++dOSIvbUAAFAfhBtU0aOHuQX88GHpww/trgYAAM8RblCFwyENHWrW58+3sxIAAOqHcIPTuLqmFi40d04BABBICDc4TWamdMYZ0v790qef2l0NAACeIdzgNBER0qBBZp27pgAAgYZwg2q5uqbmz5csy9ZSAADwCOEG1frpT6VmzaTt26WCArurAQDAfYQbVKtpU2nAALPOXVMAgEBCuEGNmK0YABCICDeo0cCBZnDx+vXSpk12VwMAgHsIN6hRq1bS5Zebda7eAAACBeEGtaJrCgAQaAg3qNXgwebrF19Iu3fbWwsAAO4g3KBWyclSerpZX7jQ3loAAHAH4QZ1omsKABBICDeokyvcfPSRdOCAraUAAFAnwg3qdN55UufO5gnhixbZXQ0AALUj3MAtdE0BAAIF4QZuGTrUfF28WDpyxNZSAACoFeEGbunZU0pNlcrKpKVL7a4GAICaEW7gFofjxNUbuqYAAI0Z4QZuc427WbjQDC4GAKAxItzAbZmZ0hlnSPv3S59+anc1AABUj3ADt0VESIMGmXW6pgAAjRXhBh5xjbuZP1+yLDsrAQCgeoQbeOSqq6RmzaTt26U1a+yuBgCA0xFu4JGmTaUBA8w6XVMAgMaIcAOPMVsxAKAxI9zAYwMHmsHF69dLmzbZXQ0AAFURbuCxVq2kfv3M+vz5dlYCAMDpGkW4mT59utLS0hQdHa309HStWrXKrfe9+eabcjgcGuq6hQd+Q9cUAKCxsj3czJ07Vzk5OZo4caIKCgrUtWtX9e/fX3v27Kn1fVu3btV9992nzMxMP1WKkw0ZYr6uXCkVFtpbCwAAJ7M93Dz99NO6/fbbNXr0aHXu3FkvvPCCmjVrptmzZ9f4HqfTqZtvvlmTJk1S+/bt/VgtXJKTpfR0s75ggb21AABwMlvDTXl5uVavXq2srKzKbWFhYcrKytLKlStrfN8jjzyis846S7fddludn3H06FGVlpZWWeAddE0BABojW8PNvn375HQ6lZCQUGV7QkKCioqKqn3Pp59+qr/97W+aNWuWW5+Rm5ur2NjYyiU1NbXBdcNwhZuPPpIOHLC1FAAAKtneLeWJgwcP6uc//7lmzZql+Ph4t94zfvx4lZSUVC47duzwcZWh47zzpE6dzBPC33vP7moAADAi7Pzw+Ph4hYeHq7i4uMr24uJiJSYmntb++++/19atWzXI9fRGSRUVFZKkiIgIbdy4UR06dKjynqioKEVFRfmgekjm6s2GDaZr6qab7K4GAACbr9xERkaqZ8+eys/Pr9xWUVGh/Px8ZWRknNb+/PPP17p167R27drKZfDgwbr88su1du1aupxs4Oqaev996cgRe2sBAECy+cqNJOXk5GjUqFHq1auX+vTpo2nTpqmsrEyjR4+WJI0cOVLJycnKzc1VdHS0Lrzwwirvj4uLk6TTtsM/evaUUlOlHTukpUulky6qAQBgC9vDzfDhw7V3715NmDBBRUVF6tatmxYvXlw5yHj79u0KCwuooUEhxeGQhg6VnnvOdE0RbgAAdnNYlmXZXYQ/lZaWKjY2ViUlJYqJibG7nKDw0UfSlVdKZ5whFRWZ504BAOBNnvz95pIIGuzSS6XWraX9+6XPPrO7GgBAqCPcoMEiIk50RzGhHwDAboQbeMXJsxWHVkcnAKCxIdzAK666SmrWTNq+XVqzxu5qAAChjHADr2jaVBowwKzTNQUAsBPhBl4zdKj5On++nVUAAEId4QZec+21ZnDxN99ImzfbXQ0AIFQRbuA1rVpJ/fqZdbqmAAB2IdzAq06+awoAADsQbuBVQ4aYrytXSoWF9tYCAAhNhBt4VXKylJ5u1hcutLcWAEBoItzA61x3TdE1BQCwA+EGXucad/PRR1JJib21AABCD+EGXtexo9Spk3TsmLRokd3VAABCDeEGPsFdUwAAuxBu4BOucPP++9KRI/bWAgAILYQb+ETPnlJKilRWJuXn210NACCUEG7gEw4Hd00BAOxBuIHPuLqmFi6Ujh+3txYAQOgg3MBnLr1Uat1a2rdP+uwzu6sBAIQKwg18JiJCGjTIrD/3nDRnjrR8ueR02loWACDIEW7gU4mJ5uu770o33SRdfrmUlibl5dlaFgAgiBFu4DN5edITT5y+fdcuadgwAg4AwDcIN/AJp1MaO1ayrNNfc20bN44uKgCA9xFu4BMrVkg7d9b8umVJO3aYdgAAeBPhBj5RWOjddgAAuItwA59ISvJuOwAA3EW4gU9kZprHLzgc1b/ucEipqaYdAADeRLiBT4SHS888Y9ZPDTiu76dNM+0AAPAmwg18JjtbeucdKTm56vYWLcz27Gx76gIABDfCDXwqO1vaulVatszc+i1JcXEnHqoJAIC3EW7gc+HhUr9+0uTJUsuW5hbwlSvtrgoAEKwIN/Cbpk1PPCl8zhx7awEABC/CDfxqxAjz9e23pePH7a0FABCcCDfwqyuvlM44Q9qzx4zDAQDA2wg38KsmTaTrrzfrdE0BAHyBcAO/c3VN5eVJR4/aWwsAIPgQbuB3l1xi5r4pKZEWL7a7GgBAsCHcwO/CwqThw806XVMAAG8j3MAWrq6phQulQ4fsrQUAEFwIN7BFz55Shw7SkSMm4AAA4C2EG9jC4Thx9ebNN+2tBQAQXAg3sI0r3CxeLP3wg721AACCB+EGtuncWerSRTp2zNwWDgCANxBuYCu6pgAA3ka4ga1uvNF8XbZMKiqytxYAQHAg3MBWZ58t/eQnUkWF9NZbdlcDAAgGhBvYznX1hq4pAIA3EG5guxtuMLMWr1wpbd1qdzUAgEDXKMLN9OnTlZaWpujoaKWnp2vVqlU1ts3Ly1OvXr0UFxen5s2bq1u3bnrttdf8WC28LSlJ6tfPrHP1BgDQULaHm7lz5yonJ0cTJ05UQUGBunbtqv79+2vPnj3Vtm/durX+8Ic/aOXKlfrXv/6l0aNHa/To0frggw/8XDm8ydU1xbOmAAAN5bAsy/L0Ta+88ori4+M1cOBASdLvf/97vfjii+rcubPmzJmjdu3aub2v9PR09e7dW88//7wkqaKiQqmpqbrnnnv0wAMPuLWPHj16aODAgXr00UfrbFtaWqrY2FiVlJQoJibG7TrhWz/8ICUmmjlv1q83c+AAAODiyd/vel25mTx5spo2bSpJWrlypaZPn64nnnhC8fHx+s1vfuP2fsrLy7V69WplZWWdKCgsTFlZWVq5cmWd77csS/n5+dq4caMuvfTSatscPXpUpaWlVRY0Pq1bS/37m3W6pgAADVGvcLNjxw6dc845kqT58+fruuuu0x133KHc3FytWLHC7f3s27dPTqdTCQkJVbYnJCSoqJZJT0pKStSiRQtFRkZq4MCBeu655/TTn/602ra5ubmKjY2tXFJTU92uD/51cteU59cTAQAw6hVuWrRoof3790uSlixZUhksoqOjdeTIEe9VV4OWLVtq7dq1+uqrr/TYY48pJydHy5cvr7bt+PHjVVJSUrns2LHD5/WhfoYMkZo2lTZvlgoK7K4GABCoIurzpp/+9Kf65S9/qe7du+u7777TNddcI0lav3690tLS3N5PfHy8wsPDVVxcXGV7cXGxEhMTa3xfWFhY5ZWjbt26acOGDcrNzVU/1y03J4mKilJUVJTbNcE+LVpIgwaZyfzmzJF69rS7IgBAIKrXlZvp06crIyNDe/fu1bvvvqszzjhDkrR69WqNcD0syA2RkZHq2bOn8vPzK7dVVFQoPz9fGRkZbu+noqJCR48edf8A0Gi5uqbmzjWzFgMA4Kl6XbmJi4urvLvpZJMmTfJ4Xzk5ORo1apR69eqlPn36aNq0aSorK9Po0aMlSSNHjlRycrJyc3MlmTE0vXr1UocOHXT06FG99957eu211zRjxoz6HAoamauvlmJipJ07pU8/lWoYJw4AQI3qFW4WL16sFi1a6JJLLpFkruTMmjVLnTt31vTp09WqVSu39zV8+HDt3btXEyZMUFFRkbp166bFixdXDjLevn27wsJOXGAqKyvTXXfdpZ07d6pp06Y6//zz9frrr2v48OH1ORQ0MtHRUna29PLL5q4pwg0AwFP1muemS5cuevzxx3XNNddo3bp16t27t3JycrRs2TKdf/75eumll3xRq1cwz03jt2SJuS08Pl7avVtq0sTuigAAdvPk73e9rtxs2bJFnf83y9q7776ra6+9VpMnT1ZBQUHl4GKgvq64QjrzTGnvXik/XxowwO6KAACBpF4DiiMjI3X48GFJ0tKlS3XVVVdJMo9GYJI8NFREhHT99WadCf0AAJ6qV7i55JJLlJOTo0cffVSrVq2qfAzDd999p5SUFK8WiNDkuulu3jzpxx/trQUAEFjqFW6ef/55RURE6J133tGMGTOUnJwsSXr//fc1gD4EeEHfvlJKilRaKr33nt3VAAACSb0GFAcyBhQHjt/9Tpo61XRRvfWW3dUAAOzk8wHFkuR0OjV//nxt2LBBknTBBRdo8ODBCg8Pr+8ugSpGjDDh5u9/lw4elFq2tLsiAEAgqFe31ObNm9WpUyeNHDlSeXl5ysvL0y233KILLrhA33//vbdrRIjq3l0691wz5mbBArurAQAEinqFm3vvvVcdOnTQjh07VFBQoIKCAm3fvl1nn3227r33Xm/XiBDlcJwYWDxnjr21AAACR73G3DRv3lxffPGFunTpUmX7119/rYsvvliHDh3yWoHexpibwLJhg9S5s7k9vKhI+t9jzAAAIcaTv9/1unITFRWlgwcPnrb90KFDioyMrM8ugWp16iR17SodPy69+67d1QAAAkG9ws21116rO+64Q19++aUsy5JlWfriiy/061//WoMHD/Z2jQhxdE0BADxRr3Dz7LPPqkOHDsrIyFB0dLSio6PVt29fnXPOOZo2bZqXS0Socz0T9eOPzbOmAACoTb1uBY+Li9OCBQu0efPmylvBO3XqpHPOOcerxQGSlJYmZWRIK1ea+W7GjbO7IgBAY+Z2uMnJyan19WXLllWuP/300/WvCKjGiBEm3MyZQ7gBANTO7XCzZs0at9o5HI56FwPU5IYbTKhZtUr6/nupQwe7KwIANFZuh5uTr8wA/paQIF1xhbR0qTR3rvTgg3ZXBABorOo1oBiww403mq/cNQUAqA3hBgEjO1tq0kT65huzAABQHcINAkarVtLVV5v1N9+0txYAQONFuEFAOblryvMHhwAAQgHhBgFl8GCpWTPpP/+RvvrK7moAAI0R4QYBpXlzE3AkuqYAANUj3CDguLqm5s6VnE57awEAND6EGwScAQOkuDjznKkVK+yuBgDQ2BBuEHCiosxt4RJz3gAATke4QUBydU2984507Ji9tQAAGhfCDQLS5ZdLZ50l/fCD9OGHdlcDAGhMCDcISBER5mGaEl1TAICqCDcIWCNGmK/z50tHjthaCgCgEXH7qeBAY/OTn0ht20rbt0tPPCGdd56UlCRlZkrh4XZXBwCwC+EGASssTOrRw4Sbhx8+sT0lRXrmmRN3VAEAQgvdUghYeXnSggWnb9+1Sxo2zLwOAAg9hBsEJKdTGju2+odnuraNG8cMxgAQigg3CEgrVkg7d9b8umVJO3YwgzEAhCLCDQJSYaF32wEAggfhBgEpKcm77QAAwYNwg4CUmWnuinI4qn/d4ZBSU007AEBoIdwgIIWHm9u9pZoDzrRpzHcDAKGIcIOAlZ1tHpyZnHz6a717M88NAIQqwg0CWna2tHWrtGyZ9MYb0uzZZnK/VaukDz6wuzoAgB2YoRgBLzxc6tfvxPfr1kl//rN0771mPTLSttIAADbgyg2CzsSJUkKC9N13ZtwNACC0EG4QdGJjpccfN+uPPmoexwAACB2EGwSln/9cysiQDh2Sfv97u6sBAPgT4QZBKSxMev55c5v4G29In3xid0UAAH8h3CBo9egh3XGHWb/nHun4cXvrAQD4B+EGQe2xx6RWraR//Ut64QW7qwEA+APhBkHtjDNMwJGkhx6S9u61tx4AgO8RbhD07rhD6tZNOnBAevBBu6sBAPhaowg306dPV1pamqKjo5Wenq5Vq1bV2HbWrFnKzMxUq1at1KpVK2VlZdXaHggPN4OLJelvf5O++sreegAAvmV7uJk7d65ycnI0ceJEFRQUqGvXrurfv7/27NlTbfvly5drxIgRWrZsmVauXKnU1FRdddVV2sVkJqjFxReb28MtS7r7bqmiwu6KAAC+4rAsy7KzgPT0dPXu3VvP/++f1hUVFUpNTdU999yjBx54oM73O51OtWrVSs8//7xGjhxZZ/vS0lLFxsaqpKREMTExDa4fgaOwUOrYUTp40FzB+cUv7K4IAOAuT/5+23rlpry8XKtXr1ZWVlbltrCwMGVlZWnlypVu7ePw4cM6duyYWrduXe3rR48eVWlpaZUFoSkpyTyaQZIeeMCMwQEABB9bw82+ffvkdDqVkJBQZXtCQoKKiorc2sf999+vNm3aVAlIJ8vNzVVsbGzlkpqa2uC6EbjuvVfq1MncNeUKOgCA4GL7mJuGmDJlit58803NmzdP0dHR1bYZP368SkpKKpcdO3b4uUo0Jk2aSM8+a9anTzdPDQcABBdbw018fLzCw8NVXFxcZXtxcbESExNrfe/UqVM1ZcoULVmyRBdddFGN7aKiohQTE1NlQWjLypKuu05yOs3MxfaOOgMAeJut4SYyMlI9e/ZUfn5+5baKigrl5+crIyOjxvc98cQTevTRR7V48WL16tXLH6UiyDz1lNS0qfTxx9LcuXZXAwDwJtu7pXJycjRr1iy98sor2rBhg+68806VlZVp9OjRkqSRI0dq/Pjxle0ff/xxPfTQQ5o9e7bS0tJUVFSkoqIiHTp0yK5DQABq105y/Wd1333m6eEAgOBge7gZPny4pk6dqgkTJqhbt25au3atFi9eXDnIePv27SosLKxsP2PGDJWXl2vYsGFKSkqqXKZOnWrXISBA/e53Uvv20q5dJx7RAAAIfLbPc+NvzHODky1cKA0ZYgYaf/ONdN55dlcEAKhOwMxzA9ht0CDp6qulY8eksWMZXAwAwYBwg5DmcEjTppkrN4sXS3//u90VAQAainCDkHfeedJvf2vWx42TfvzR1nIAAA1EuAEk/eEPUnKytGWL9OSTdlcDAGgIwg0gqUULyXXD3eTJ0rZt9tYDAKg/wg3wP8OHS5ddZrqlXN1UAIDAQ7gB/sfhkJ57TgoPl959V1q61O6KAAD1QbgBTtKlizRmjFm/5x6pvNzeegAAniPcAKeYNEk680zp3/82V3IAAIElwu4CgMYmLk6aMkW67Tbp4YeltDRzBScpScrMNN1WAIDGi8cvANWoqJA6dpQ2b666PSVFeuYZKTvbnroAIFTx+AWggebPPz3YSOYhm8OGSXl5fi8JAOAmwg1wCqfTPGeqOq7rnOPGmXYAgMaHcAOcYsUKaefOml+3LGnHDtMOAND4EG6AUxQWercdAMC/CDfAKZKSvNsOAOBfhBvgFJmZ5q4oh6PmNikpph0AoPEh3ACnCA83t3tLNQeczp2Z7wYAGivCDVCN7GzpnXek5OSq2+PjzdclS6TZs/1fFwCgboQboAbZ2dLWrdKyZdIbb5ivRUXSo4+a1++6S/rnP20tEQBQDWYoBjxUUSH97GfSwoVSaqq0erV5FhUAwHeYoRjwobAw6dVXpXPPNfPd3HijdPy43VUBAFwIN0A9xMZK8+ZJzZtLH30kPfig3RUBAFwIN0A9XXCB9NJLZv3JJ6W337a3HgCAQbgBGuD666Xf/c6sjx4trV9vbz0AAMIN0GCTJ0tXXimVlZmBxiUldlcEAKGNcAM0UESENGeO1LattGmTNHKkuaMKAGAPwg3gBWeeKb37rhQVZW4RnzzZ7ooAIHQRbgAv6dVLmjHDrE+YIL3/vr31AECoItwAXjR6tPTrX0uWJd10k/T993ZXBAChh3ADeNm0adJPfiIdOGAGGJeV2V0RAIQWwg3gZVFR5qGbZ50lrVsn3XGHuZIDAPAPwg3gA8nJZlK/iAjz0M1nn7W7IgAIHYQbwEcuvVR66imz/tvfSh9/bG89ABAqCDeAD91zj3TzzZLTKd1wg7Rrl90VAUDwI9wAPuRwSC++KHXtKu3ZIw0bJh09andVABDcCDeAjzVrJuXlSXFx0hdfSGPH2l0RAAQ3wg3gB+3bm4HFDoc0c6b0t7/ZXREABC/CDeAnV18tPfKIWR8zRvrqK3vrAYBgRbgB/OjBB6XBg824m+uuk4qKpOXLzYM3ly83A48BAA0TYXcBQCgJC5NefVXq00f67jspLa3qAOOUFOmZZ6TsbNtKBICAx5UbwM9iY6W77jLrp945tWuXuaMqL8//dQFAsCDcAH7mdEpTp1b/musxDePG0UUFAPVFuAH8bMUKaefOml+3LGnHDtMOAOA5wg3gZ4WF3m0HAKiKcAP4WVKSe+0++EA6cMCnpQBAUCLcAH6WmWnuinI4am/3yitSu3bSxInSf//rn9oAIBgQbgA/Cw83t3tLpwcch8Ms990nXXihVFpqJv5LS5MmTJB++MHv5QJAwCHcADbIzpbeeUdKTq66PSXFbH/ySenrr816ly4m5Dz6qAk5Dz1EyAGA2tgebqZPn660tDRFR0crPT1dq1atqrHt+vXrdd111yktLU0Oh0PTpk3zX6GAl2VnS1u3SsuWmedOLVsmbdlyYgK/sDAzi/HatdK770oXXSQdPCj96U8m5Pzxj9L+/TYeAAA0UraGm7lz5yonJ0cTJ05UQUGBunbtqv79+2vPnj3Vtj98+LDat2+vKVOmKDEx0c/VAt4XHi716yeNGGG+hoef3iYszASeNWvM5H5du5qQ89hjJuT84Q+EHAA4mcOyXNOG+V96erp69+6t559/XpJUUVGh1NRU3XPPPXrggQdqfW9aWprGjRuncePGefSZpaWlio2NVUlJiWJiYupbOmCbigpp4UJp0iRzVUeSWrSQ7r5b+u1vpfj4E22dTjNfTmGhuUsrM7P6AAUAjZ0nf79tu3JTXl6u1atXKysr60QxYWHKysrSypUrvfY5R48eVWlpaZUFCGRhYdLQoVJBgTR/vtS9u3TokDRlirmS88AD0t695ipPWpp0+eXSTTeZr2lpPNoBQPCzLdzs27dPTqdTCQkJVbYnJCSoqKjIa5+Tm5ur2NjYyiU1NdVr+wbs5HBIQ4ZIq1dLCxZIPXpIZWXS449LqalmvM6pMyHz7CoAocD2AcW+Nn78eJWUlFQuO3bssLskwKscDmnwYOmf/zTdVT16nP5ATheeXQUgFETY9cHx8fEKDw9XcXFxle3FxcVeHSwcFRWlqKgor+0PaKwcDmnQIDP+5ooram538rOr+vXzW3kA4De2XbmJjIxUz549lZ+fX7mtoqJC+fn5ysjIsKssIOC526vLs6sABCvbrtxIUk5OjkaNGqVevXqpT58+mjZtmsrKyjR69GhJ0siRI5WcnKzc3FxJZhDyt99+W7m+a9curV27Vi1atNA555xj23EAjYm7z65ytx0ABBpbw83w4cO1d+9eTZgwQUVFRerWrZsWL15cOch4+/btCgs7cXFp9+7d6t69e+X3U6dO1dSpU3XZZZdp+fLl/i4faJRcz67atevEGJtTxcWZdgAQjGyd58YOzHODUJCXZ+6KkmoOOL//vbl9vK4HeAJAYxAQ89wA8J2anl2VmirdcotZf+IJ6dZbpWPH/F4eAPiUrd1SAHwnO9vMg1PdDMVXXin98pfSq6+aCf/efltq3tzuigHAO+iWAkLUokXS9ddLR45I6enSP/5R9dENANCY0C0FoE4DB0r5+VLr1tKXX0qXXCJt22Z3VQDQcIQbIIRlZEiffmrG4mzcKPXtK61bZ3dVANAwhBsgxHXqJH3+uXTBBdLu3WZczief2F0VANQf4QaAUlLMwONLLpFKSqSrrpLmzbO7KgCoH8INAElSq1bSkiXmDqujR808OTNn2l0VAHiOcAOgUtOmZn6c22+XKiqkX/9amjSp5okAAaAxItwAqCIiwlyxmTDBfP/ww9Kdd0pOp61lAYDbCDcATuNwmCs2f/mLWZ85U7rhBunHH+2uDADqRrgBUKM775TeekuKjDTPq+rfXzpwwO6qAKB2hBsAtRo2TPrgAykmxtwifuml5pZxyXRVLV8uzZljvtJ1BaAxINwAqFO/fibYJCaaSf769pWee05KS5Muv1y66SbzNS3NXOEBADvxbCkAbtuyxXRNbdpU/esOh/n6zjvmwZ0A4C08WwqAT5x9trmC06RJ9a+7/qk0blzDu6jo8gJQX4QbAB7597+lY8dqft2ypB07pL/+Vdq5Uyov9/wz8vLo8gJQfxF2FwAgsBQWutfu178+sd66tRmvU92SkHBiPT5emj/fDGI+tcN81y6znS4vAHUh3ADwSFKSe+3i481t48ePSz/8YJZvv639PWH/u5Zc3UhAyzJjesaNM4+ICA/3pGoAoYRwA8AjmZnmQZu7dlUfQhwO8/qWLWb9hx+k4mKpqKj6xfXa3r3mkQ+1cXV5rVhh7uACgOoQbgB4JDxceuYZ00XkcFQNOK67paZNO3FlJT7eLBdcUPt+jx2TZs2Sxoypu4adO+tVOoAQwYBiAB7LzjZjX5KTq25PSan/mJgmTaTOnd1r+9BDZmJBAKgO89wAqDen03QRFRaasTiZmQ0bC+N0mruiaurykqpeLerfX5o6Vbrwwvp/JoDAwDw3APwiPNyMfRkxwnxt6CBfV5eXdKKLy8XhMMvLL0s5OeZKzwcfSF27SnfcYcbtAIBEuAHQyNTV5TVypPTUU9KGDdJ115lByLNmSeeeK/3pT9Lhw/bUDaDxoFsKQKPkbpfXp59Kv/2ttGqV+T4lRXrsMemWW07cWg4g8Hny95twAyDgVVRIc+dK48dL27aZbT16mCs83DIOBAfG3AAIKWFhZtzPv/8tTZkitWwpFRSYxzYMHSp9953dFQLwJ8INgKARHS3df7+0ebN0552mG2vBAjPHzr33Svv3n2jLgzmB4EW3FICgtWGD9LvfSYsWme9jY6U//lFKTZXuu6/qZIApKeZOLZ5bBTROjLmpBeEGCD35+WbQ8ddf19zGdes5D+YEGifG3ADASa68Ulq9WvrrX2u+g8r1z7xx4wKji4puNaBmhBsAISE8XOrQofaHc7oezDltWtXxOfXhy/CRl2dmcr78cummm8zXtDSzHQDhBkAIKSx0r91995mHfaamSoMHSxMmSPPmSVu31vxYiJP5Mnzk5ZmHlp768NBdu8x2Ag7AmBu7ywHgR8uXm6BRlzZtpN27q38tLk7q1s0s3bubr506mcdBSCfCx6n/Z/XGmB7Xs7dqeiq6w2EGRm/Z0vBnfHnzmWGANzCguBaEGyB01fVgzpPDQVmZGYC8dq20Zo35+s030rFjp78vKso8vPOii8wVngMHqv981/43bpSOHDGfcehQ3Yur3ZYt0ief1H2cb75pAlZ9AklenjR2LHeSofEh3NSCcAOENteVFalqwHHnykp5ufTttycCjyv0HDzoy4rrJyJCattWOvtss6SlVV1PTDz94aS+vOoENBThphaEGwDVXZ1ITTUDiT39411RYa6orF0rvf66NH+++++NjJRatKh9ad78xPru3Seeml6b8PC6BzBHR58IPGlpUrt20pNP1jyQ2ltdXhLdXqgfwk0tCDcAJN/8gXV3TM/f/y71739inI673O1W27xZKi42A6C3bDmxuL7fubP2u8ZqM3GilJVlfmZJSVKzZp69n24v1BfhphaEGwC+4smYnvoGqYZ0q7mUl5twcXLwWb5c+vxzz+uJjT0RdGpbYmLMeCS6vVBfhJtaEG4A+JI3woc7n+GtbjUXd686XXihdPiwueJ15Ij7+4+ONoOxa+ou82a3F4IT4aYWhBsAvuaL8HEqb3ereXrVybKk0lIzDqiwsPaltNT9OkaPNj+jbt2k5OTTBz27eyyM6Qk+hJtaEG4A+EMg/oH11VWnw4elF1+UfvMbz94XH2/mEnIt3bpJ555b+8/RH2N6AvHcuvi6dl/u36O/31aIKSkpsSRZJSUldpcCAI3Ou+9aVkqKZZl4Y5bUVLO9IZYtq7rPmpaf/tSyLrzQssLDq3+9eXPLysiwrLvusqxZsyzrn/+0rCNHTtTucJz+HofDLA09BtdnnPrzSUnxzr4ty7KOHzc/qzfeMF+PH/fOfi3L97X7ev+e/P3myg0AoApf/Ovb026vI0fMpImu+YTWrJH+9a/qx/lEREjnny/95z/mKlF1vDmY21cDon151ckftft6sDjdUrUg3ACAPRra7eV0St99VzXwrFkj/fCD+zX06GHGP7nmD2re/MRS2/fR0dIll9T8WI6GhidfhYOjR82M2d26SUVF1bdxOKSEBDP7tetYo6PNzNvuHIu/HgtCuKkF4QYA7OPtwdaWZfb1zDPSU095rcx669HDPJusaVMTEJo2rbpUt61JE+m226S9e2ve7xlnSFOmmEdxHDxoHsdx8GDd69U9LsQTTZqYkOMKPCcHH9d6WZn0xRd172vZMqlfv/rXQripBeEGAOxl5wSKDz5oHktRVnZicT2/q7bvS0vrnvU50EVFmTBU3wke6/LGG9KIEfV/vyd/vyPq/zEAAHguPLxh/4KvTmam6fqoa0zPI4/UL0h5Ep7atzdjg05efvyx5m27dpnZo+vSrZvUsaPUsqXpMmvZ8sRy8venrq9ebWaVrsvixea8HD9uavvxR9Ot5VqvadvatebRHXVJSqq7jdd4Zwxzwzz//PNWu3btrKioKKtPnz7Wl19+WWv7t956y+rYsaMVFRVlXXjhhdaiRYvc/izulgKA4OS6W+rUO6a8cbfU8ePmzp/q7sZyfUZqav3ubnL3TrJlyxpf7f7Yv4snf7/D/JijqjV37lzl5ORo4sSJKigoUNeuXdW/f3/t2bOn2vaff/65RowYodtuu01r1qzR0KFDNXToUH3zzTd+rhwA0JhkZ5uBt8nJVbenpDT8bp3w8BMPLT11YkHX99Om1e+qkOuqU00TFjocZlxSZqbn+5Z8W7s/9l8vDctRDdenTx9rzJgxld87nU6rTZs2Vm5ubrXtb7jhBmvgwIFVtqWnp1u/+tWv3Po8rtwAQHDz91wx3pgHyJdXnXxdu7/2HzDz3JSXl6tZs2Z65513NHTo0Mrto0aN0oEDB7RgwYLT3tO2bVvl5ORo3LhxldsmTpyo+fPn6+uvvz6t/dGjR3X06NHK70tLS5WamsqAYgBAvfhqFt5AfGyHP/cfMAOK9+3bJ6fTqYSEhCrbExIS9O9//7va9xQVFVXbvqiGG/hzc3M1adIk7xQMAAh5vhgQLZkAM2SIb8OHr2r31/7dFfR3S40fP145OTmV37uu3AAA0Ng0lnAQ6GwNN/Hx8QoPD1dxcXGV7cXFxUpMTKz2PYmJiR61j4qKUlRUlHcKBgAAjZ6td0tFRkaqZ8+eys/Pr9xWUVGh/Px8ZWRkVPuejIyMKu0l6cMPP6yxPQAACC22d0vl5ORo1KhR6tWrl/r06aNp06aprKxMo0ePliSNHDlSycnJys3NlSSNHTtWl112mZ566ikNHDhQb775pv75z3/qxRdftPMwAABAI2F7uBk+fLj27t2rCRMmqKioSN26ddPixYsrBw1v375dYWEnLjD17dtXb7zxhv74xz/qwQcf1Lnnnqv58+frwgsvtOsQAABAI8KzpQAAQKPnyd9v22coBgAA8CbCDQAACCqEGwAAEFQINwAAIKjYfreUv7nGT5eWltpcCQAAcJfr77Y790GFXLg5ePCgJPEIBgAAAtDBgwcVGxtba5uQuxW8oqJCu3fvVsuWLeVwOLy6b9dzq3bs2BH0t5lzrMErlI6XYw1eoXS8oXKslmXp4MGDatOmTZX576oTclduwsLClJKS4tPPiImJCer/wE7GsQavUDpejjV4hdLxhsKx1nXFxoUBxQAAIKgQbgAAQFAh3HhRVFSUJk6cqKioKLtL8TmONXiF0vFyrMErlI43lI7VXSE3oBgAAAQ3rtwAAICgQrgBAABBhXADAACCCuEGAAAEFcKNh6ZPn660tDRFR0crPT1dq1atqrX922+/rfPPP1/R0dHq0qWL3nvvPT9VWn+5ubnq3bu3WrZsqbPOOktDhw7Vxo0ba33Pyy+/LIfDUWWJjo72U8UN8/DDD59W+/nnn1/rewLxvEpSWlraacfqcDg0ZsyYatsH0nn95JNPNGjQILVp00YOh0Pz58+v8rplWZowYYKSkpLUtGlTZWVladOmTXXu19PfeX+p7XiPHTum+++/X126dFHz5s3Vpk0bjRw5Urt37651n/X5XfCHus7trbfeelrdAwYMqHO/jfHc1nWs1f3+OhwOPfnkkzXus7GeV18i3Hhg7ty5ysnJ0cSJE1VQUKCuXbuqf//+2rNnT7XtP//8c40YMUK33Xab1qxZo6FDh2ro0KH65ptv/Fy5Zz7++GONGTNGX3zxhT788EMdO3ZMV111lcrKymp9X0xMjAoLCyuXbdu2+anihrvggguq1P7pp5/W2DZQz6skffXVV1WO88MPP5QkXX/99TW+J1DOa1lZmbp27arp06dX+/oTTzyhZ599Vi+88IK+/PJLNW/eXP3799ePP/5Y4z49/Z33p9qO9/DhwyooKNBDDz2kgoIC5eXlaePGjRo8eHCd+/Xkd8Ff6jq3kjRgwIAqdc+ZM6fWfTbWc1vXsZ58jIWFhZo9e7YcDoeuu+66WvfbGM+rT1lwW58+fawxY8ZUfu90Oq02bdpYubm51ba/4YYbrIEDB1bZlp6ebv3qV7/yaZ3etmfPHkuS9fHHH9fY5qWXXrJiY2P9V5QXTZw40eratavb7YPlvFqWZY0dO9bq0KGDVVFRUe3rgXpeJVnz5s2r/L6iosJKTEy0nnzyycptBw4csKKioqw5c+bUuB9Pf+ftcurxVmfVqlWWJGvbtm01tvH0d8EO1R3rqFGjrCFDhni0n0A4t+6c1yFDhlhXXHFFrW0C4bx6G1du3FReXq7Vq1crKyurcltYWJiysrK0cuXKat+zcuXKKu0lqX///jW2b6xKSkokSa1bt6613aFDh9SuXTulpqZqyJAhWr9+vT/K84pNmzapTZs2at++vW6++WZt3769xrbBcl7Ly8v1+uuv6xe/+EWtD5EN5PPqsmXLFhUVFVU5b7GxsUpPT6/xvNXnd74xKykpkcPhUFxcXK3tPPldaEyWL1+us846Sx07dtSdd96p/fv319g2WM5tcXGxFi1apNtuu63OtoF6XuuLcOOmffv2yel0KiEhocr2hIQEFRUVVfueoqIij9o3RhUVFRo3bpwuvvhiXXjhhTW269ixo2bPnq0FCxbo9ddfV0VFhfr27audO3f6sdr6SU9P18svv6zFixdrxowZ2rJlizIzM3Xw4MFq2wfDeZWk+fPn68CBA7r11ltrbBPI5/VkrnPjyXmrz+98Y/Xjjz/q/vvv14gRI2p9sKKnvwuNxYABA/Tqq68qPz9fjz/+uD7++GNdffXVcjqd1bYPlnP7yiuvqGXLlsrOzq61XaCe14YIuaeCwzNjxozRN998U2f/bEZGhjIyMiq/79u3rzp16qSZM2fq0Ucf9XWZDXL11VdXrl900UVKT09Xu3bt9NZbb7n1L6JA9be//U1XX3212rRpU2ObQD6vMI4dO6YbbrhBlmVpxowZtbYN1N+FG2+8sXK9S5cuuuiii9ShQwctX75cV155pY2V+dbs2bN188031znIP1DPa0Nw5cZN8fHxCg8PV3FxcZXtxcXFSkxMrPY9iYmJHrVvbO6++2794x//0LJly5SSkuLRe5s0aaLu3btr8+bNPqrOd+Li4nTeeefVWHugn1dJ2rZtm5YuXapf/vKXHr0vUM+r69x4ct7q8zvf2LiCzbZt2/Thhx/WetWmOnX9LjRW7du3V3x8fI11B8O5XbFihTZu3Ojx77AUuOfVE4QbN0VGRqpnz57Kz8+v3FZRUaH8/Pwq/7I9WUZGRpX2kvThhx/W2L6xsCxLd999t+bNm6ePPvpIZ599tsf7cDqdWrdunZKSknxQoW8dOnRI33//fY21B+p5PdlLL72ks846SwMHDvTofYF6Xs8++2wlJiZWOW+lpaX68ssvazxv9fmdb0xcwWbTpk1aunSpzjjjDI/3UdfvQmO1c+dO7d+/v8a6A/3cSubKa8+ePdW1a1eP3xuo59Ujdo9oDiRvvvmmFRUVZb388svWt99+a91xxx1WXFycVVRUZFmWZf385z+3Hnjggcr2n332mRUREWFNnTrV2rBhgzVx4kSrSZMm1rp16+w6BLfceeedVmxsrLV8+XKrsLCwcjl8+HBlm1OPddKkSdYHH3xgff/999bq1autG2+80YqOjrbWr19vxyF45Le//a21fPlya8uWLdZnn31mZWVlWfHx8daePXssywqe8+ridDqttm3bWvfff/9prwXyeT148KC1Zs0aa82aNZYk6+mnn7bWrFlTeXfQlClTrLi4OGvBggXWv/71L2vIkCHW2WefbR05cqRyH1dccYX13HPPVX5f1++8nWo73vLycmvw4MFWSkqKtXbt2iq/x0ePHq3cx6nHW9fvgl1qO9aDBw9a9913n7Vy5Upry5Yt1tKlS60ePXpY5557rvXjjz9W7iNQzm1d/x1blmWVlJRYzZo1s2bMmFHtPgLlvPoS4cZDzz33nNW2bVsrMjLS6tOnj/XFF19UvnbZZZdZo0aNqtL+rbfess477zwrMjLSuuCCC6xFixb5uWLPSap2eemllyrbnHqs48aNq/y5JCQkWNdcc41VUFDg/+LrYfjw4VZSUpIVGRlpJScnW8OHD7c2b95c+XqwnFeXDz74wJJkbdy48bTXAvm8Llu2rNr/bl3HU1FRYT300ENWQkKCFRUVZV155ZWn/QzatWtnTZw4scq22n7n7VTb8W7ZsqXG3+Nly5ZV7uPU463rd8EutR3r4cOHrauuuso688wzrSZNmljt2rWzbr/99tNCSqCc27r+O7Ysy5o5c6bVtGlT68CBA9XuI1DOqy85LMuyfHppCAAAwI8YcwMAAIIK4QYAAAQVwg0AAAgqhBsAABBUCDcAACCoEG4AAEBQIdwAAICgQrgBAABBhXADwOv69euncePG2V0GgBDFDMUAvO6HH35QkyZN1LJlywbvy+FwaN68eRo6dGjDCwMQEiLsLgBA8GndurXdJQAIYXRLAfC6k7ul0tLSNHnyZP3iF79Qy5Yt1bZtW7344ouVbcvLy3X33XcrKSlJ0dHRateunXJzcyvfK0k/+9nP5HA4Kr///vvvNWTIECUkJKhFixbq3bu3li5dWqWGuj5Xknbu3KkRI0aodevWat68uXr16qUvv/yy8vUFCxaoR48eio6OVvv27TVp0iQdP35ckmRZlh5++GG1bdtWUVFRatOmje69915v/hgB1BPhBoDPPfXUU+rVq5fWrFmju+66S3feeac2btwoSXr22We1cOFCvfXWW9q4caP+7//+rzLEfPXVV5Kkl156SYWFhZXfHzp0SNdcc43y8/O1Zs0aDRgwQIMGDdL27dvd/txDhw7psssu065du7Rw4UJ9/fXX+v3vf6+KigpJ0ooVKzRy5EiNHTtW3377rWbOnKmXX35Zjz32mCTp3Xff1Z///GfNnDlTmzZt0vz589WlSxef/ywBuMHWZ5IDCEqXXXaZNXbsWMuyLKtdu3bWLbfcUvlaRUWFddZZZ1kzZsywLMuy7rnnHuuKK66wKioqqt2XJGvevHl1fuYFF1xgPffcc5Xf1/W5M2fOtFq2bGnt37+/2v1deeWV1uTJk6tse+2116ykpCTLsizrqaeess477zyrvLy8ztoA+BdXbgD43EUXXVS57nA4lJiYqD179kiSbr31Vq1du1YdO3bUvffeqyVLltS5v0OHDum+++5Tp06dFBcXpxYtWmjDhg2nXbmp7XPXrl2r7t271zg+6Ouvv9YjjzyiFi1aVC633367CgsLdfjwYV1//fU6cuSI2rdvr9tvv13z5s2r7LICYC/CDQCfa9KkSZXvHQ5HZfdPjx49tGXLFj366KM6cuSIbrjhBg0bNqzW/d13332aN2+eJk+erBUrVmjt2rXq0qWLysvL3f7cpk2b1voZhw4d0qRJk7R27drKZd26ddq0aZOio6OVmpqqjRs36i9/+YuaNm2qu+66S5deeqmOHTvm1s8EgO9wtxQA28XExGj48OEaPny4hg0bpgEDBuiHH35Q69at1aRJEzmdzirtP/vsM91666362c9+JskEka1bt3r0mRdddJH++te/Vn7OqXr06KGNGzfqnHPOqXEfTZs21aBBgzRo0CCNGTNG559/vtatW6cePXp4VAsA7yLcALDV008/raSkJHXv3l1hYWF6++23lZiYqLi4OEnmrqf8/HxdfPHFioqKUqtWrXTuuecqLy9PgwYNksPh0EMPPVR5RcZdI0aM0OTJkzV06FDl5uYqKSlJa9asUZs2bZSRkaEJEybo2muvVdu2bTVs2DCFhYXp66+/1jfffKM//elPevnll+V0OpWenq5mzZrp9ddfV9OmTdWuXTsf/JQAeIJuKQC2atmypZ544gn16tVLvXv31tatW/Xee+8pLMz87+mpp57Shx9+qNTUVHXv3l2SCUStWrVS3759NWjQIPXv39/jqyWRkZFasmSJzjrrLF1zzTXq0qWLpkyZovDwcElS//799Y9//ENLlixR79699ZOf/ER//vOfK8NLXFycZs2apYsvvlgXXXSRli5dqr///e8644wzvPjTAVAfzFAMAACCClduAABAUCHcAACAoEK4AQAAQYVwAwAAggrhBgAABBXCDQAACCqEGwAAEFQINwAAIKgQbgAAQFAh3AAAgKBCuAEAAEHl/wFeBbxouGacYgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleAttention(\n",
              "  (W_y): Linear(in_features=3, out_features=1, bias=False)\n",
              "  (tanh): Tanh()\n",
              "  (softmax): Softmax(dim=0)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_model(model, data, epochs=20, learning_rate=0.4):\n",
        "    torch.random.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(),\n",
        "                                 lr=learning_rate)\n",
        "    model.verbose = False\n",
        "    loss_val = []\n",
        "    # main training loop\n",
        "    for epoch in tqdm(range(epochs), total=epochs):\n",
        "        np.random.shuffle(data)\n",
        "        optimizer.zero_grad() # reset all the gradient information\n",
        "        for X, y in data:\n",
        "            result = model.forward(X)\n",
        "            loss = criterion(result[0], y)\n",
        "            loss.backward()      # computes all the gradients\n",
        "        optimizer.step()     # update parameters\n",
        "        loss_val.append(loss.item())\n",
        "    plt.figure()\n",
        "    plt.plot(loss_val, 'bo-')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('instances')\n",
        "    plt.show()\n",
        "    return model\n",
        "\n",
        "\n",
        "att = SimpleAttention(input_size=3)\n",
        "train_model(att, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3h54hFFuvHdA",
        "outputId": "b06d4386-b6e2-4a62-b1f9-867b9a690886",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input=\n",
            " tensor([[1., 0., 0.],\n",
            "        [0., 0., 1.],\n",
            "        [1., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64)\n",
            "s=\n",
            " tensor([ 0.9950, -0.9995,  0.9950, -0.9995], dtype=torch.float64,\n",
            "       grad_fn=<TanhBackward0>)\n",
            "alpha=\n",
            " tensor([0.4401, 0.0599, 0.4401, 0.0599], dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "a=\n",
            " tensor([0.8802, 0.0000, 0.1198], dtype=torch.float64,\n",
            "       grad_fn=<SqueezeBackward4>)\n",
            "y=\n",
            " tensor([0.9948], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9948], dtype=torch.float64, grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "att.verbose=True\n",
        "# input is a,c,a,c\n",
        "print('input=\\n', X[0])\n",
        "att.forward(X[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XbDtj-ZFvHdA",
        "outputId": "2827a4a8-0308-40cd-8376-165412c2a9c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([ 2.9987,  3.8993, -4.1379], dtype=torch.float64, requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "att.W_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "X5yneEkkvHdA",
        "outputId": "34a572a8-9bc2-4b11-a607-90833e5710a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 5.7664, -5.7506,  1.5511]], dtype=torch.float64, requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "att.W_y.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SH2K0nUovHdA",
        "outputId": "3f25108b-09e9-4c40-8daf-56084c9805a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s=\n",
            " tensor([ 0.9950, -0.9995,  0.9950, -0.9995,  0.9950, -0.9995,  0.9950, -0.9995,\n",
            "         0.9950, -0.9995], dtype=torch.float64, grad_fn=<TanhBackward0>)\n",
            "alpha=\n",
            " tensor([0.1760, 0.0240, 0.1760, 0.0240, 0.1760, 0.0240, 0.1760, 0.0240, 0.1760,\n",
            "        0.0240], dtype=torch.float64, grad_fn=<SoftmaxBackward0>)\n",
            "a=\n",
            " tensor([0.8802, 0.0000, 0.1198], dtype=torch.float64,\n",
            "       grad_fn=<SqueezeBackward4>)\n",
            "y=\n",
            " tensor([0.9948], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9948], dtype=torch.float64, grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "att.forward(torch.tensor([a,c,a,c,a,c,a,c,a,c], dtype=torch.float64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aeLs3Qg2vHdA",
        "outputId": "df6e1384-93cd-40a4-df1c-83e6fcb91cec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s=\n",
            " tensor([0.9950, 0.9992], dtype=torch.float64, grad_fn=<TanhBackward0>)\n",
            "alpha=\n",
            " tensor([0.4990, 0.5010], dtype=torch.float64, grad_fn=<SoftmaxBackward0>)\n",
            "a=\n",
            " tensor([0.4990, 0.5010, 0.0000], dtype=torch.float64,\n",
            "       grad_fn=<SqueezeBackward4>)\n",
            "y=\n",
            " tensor([0.4990], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4990], dtype=torch.float64, grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "att.forward(torch.tensor([a,b], dtype=torch.float64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1YwQFKzvHdB"
      },
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Sources\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- https://web.stanford.edu/class/cs224n/"
      ],
      "metadata": {
        "id": "-MRdAc_O01gu"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f8OiXeEVwfGw",
        "04LxYCDQvHc8",
        "jO4DP-kjwwFG",
        "14jFC71cwyqX",
        "kapVP3M5xCIZ",
        "bnX9QdcvxEa5",
        "ixyhlyh1xISE",
        "-CO_vzVSxM5T",
        "ioD31_UvxUbm",
        "5S24YoMLzJXl",
        "V1YwQFKzvHdB"
      ],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}