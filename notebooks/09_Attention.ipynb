{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Tulane](https://github.com/tulane-cmps6730/main/blob/main/img/banner.png?raw=true)\n",
        "\n",
        "<center>\n",
        "\n",
        "<font size=\"+3\">Attention</font>\n",
        "\n",
        "[Aron Culotta](https://cs.tulane.edu/~aculotta/)  \n",
        "[Tulane University](https://cs.tulane.edu/)\n",
        "\n",
        "<a href=\"http://colab.research.google.com/github/tulane-cmps6730/main/blob/main/notebooks/09_Attention.ipynb\">\n",
        "        <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Google_Colaboratory_SVG_Logo.svg/320px-Google_Colaboratory_SVG_Logo.svg.png\"  width=10%/></a>\n",
        "<a href=\"https://github.com/tulane-cmps6730/main/tree/main\">\n",
        "        <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/GitHub_Invertocat_Logo.svg/240px-GitHub_Invertocat_Logo.svg.png\" width=6%/></a>\n",
        "\n",
        "In this module, we'll learn about attention mechanisms to better capture long-distance relationships in language sequences.\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "u7t32OQMvRZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Motivation"
      ],
      "metadata": {
        "id": "f8OiXeEVwfGw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04LxYCDQvHc8"
      },
      "source": [
        "### LSTMs as language models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> While the acting was pretty good, overall the movie was quite bad.\n",
        "\n",
        "![figs/lstmclf1.png](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/lstmclf1.png?raw=1)\n",
        "\n",
        "\n",
        "Each hidden state is now a **context-dependent** word representation.\n",
        "\n",
        "<br><br><br><br>\n",
        "\n"
      ],
      "metadata": {
        "id": "_wYMuHKrw6iX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bidirectional LSTMs"
      ],
      "metadata": {
        "id": "jO4DP-kjwwFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's no reason to limit ourselves to left-to-right ordering:\n",
        "\n",
        "![figs/lstmclf2.png](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/lstmclf2.png?raw=1)\n",
        "\n",
        "Word representation is now the concatenation of hidden vectors from both directions.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ctDXLahQwssF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTMs for Classification"
      ],
      "metadata": {
        "id": "14jFC71cwyqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![figs/lstmclf3.png](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/lstmclf3.png?raw=1)\n",
        "\n",
        "What are our options here?\n",
        "\n",
        "\n",
        "<br><br><br><br>\n",
        "\n",
        "**concatenate**: $h_1 \\oplus h_2 \\oplus \\ldots \\oplus h_n$\n",
        "\n",
        "What's wrong with this?\n",
        "\n",
        "\n",
        "<br><br><br><br>\n",
        "\n",
        "average: $\\frac{1}{n}\\sum_i^n h_i$\n",
        "\n",
        "What's wrong with this?\n",
        "\n",
        "<br><br><br><br>\n",
        "\n",
        "$h_{\\hbox{bad}}$ contributes as much to the average as $h_{\\hbox{the}}$!\n",
        "\n",
        "<br><br>\n",
        "\n",
        "How can we get something like a weighted average?\n",
        "\n",
        "$\\frac{\\sum_i^n w_i h_i}{\\sum_i^n w_i}$\n",
        "\n",
        "<br><br><br>\n",
        "We need a way to\n",
        "\n",
        "- get a fixed representation from an arbitrary list of values\n",
        "- have the representation weighted by the importance of each input value"
      ],
      "metadata": {
        "id": "Lh6cwOZJwuhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Attention\n"
      ],
      "metadata": {
        "id": "kapVP3M5xCIZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEb4XthLvHc8"
      },
      "source": [
        "\n",
        "> Given a set of vector **values**, and a vector **query**,  \n",
        "> **attention** is a technique to compute a weighted sum of the values, dependent on the query.\n",
        "\n",
        "- a selective summary of the values based on the query\n",
        "- gives a fixed-size representation of the values\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overall approach\n"
      ],
      "metadata": {
        "id": "bnX9QdcvxEa5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwkgFJPUvHc9"
      },
      "source": [
        "\n",
        "**Input**: sequence of value vectors $\\mathbf{h}_1 \\ldots \\mathbf{h}_n \\in \\mathbb{R}^{d_h}$ and a query vector $\\mathbf{q} \\in \\mathbb{R}^{d_q}$\n",
        "\n",
        "1. Compute **attention scores** $\\mathbf{s} \\in \\mathbb{R}^n$\n",
        "  - we'll see how in a moment\n",
        "\n",
        "\n",
        "2. Apply softmax to get the **attention distribution** $\\alpha$:\n",
        "  - $\\alpha = \\mathrm{softmax}(\\mathbf{s}) \\in \\mathbb{R}^n$\n",
        "  \n",
        "  \n",
        "3. Compute the **attention output**, the sum of values weighted by attention distribution:\n",
        "  - $\\mathbf{a} = \\sum_i^n \\alpha_i \\mathbf{h}_i \\in \\mathbb{R}^{d_h}$\n",
        "  - $\\mathbf{a}$ then becomes input features for classification layer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Types of attention\n"
      ],
      "metadata": {
        "id": "ixyhlyh1xISE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGVdkp1LvHc9"
      },
      "source": [
        "\n",
        "\n",
        "The attention scores should somehow combine the query vector with the value vectors to score the importance of each value. Common choices include:\n",
        "\n",
        "- **Dot product:** $~~~\\mathbf{s}_i = \\mathbf{q} \\cdot \\mathbf{h}_i \\in \\mathbb{R}$\n",
        "  - this assumes $d_h == d_q$\n",
        "\n",
        "\n",
        "- **Multiplicative attention:**   $~~~\\mathbf{s}_i = \\mathbf{q}^T \\mathbf{W} \\mathbf{h}_i \\in \\mathbb{R}$\n",
        "  - must learn the matrix $W \\in \\mathbb{R}^{d_q \\times d_h}$\n",
        "  - c.f., [`torch.nn.Bilinear`](https://pytorch.org/docs/stable/generated/torch.nn.Bilinear.html)\n",
        "  \n",
        "\n",
        "- **Additive attention:**   $~~~\\mathbf{s}_i = \\mathbf{v}^T \\mathrm{tanh}(\\mathbf{W_1} \\mathbf{h}_i  + \\mathbf{W_2}\\mathbf{q}) \\in \\mathbb{R}$\n",
        "  - must learn vector $\\mathbf{v} \\in \\mathbb{R}^{d_v}$ and the matrices $W_1 \\in \\mathbb{R}^{d_v \\times d_h}$, $W_2 \\in \\mathbb{R}^{d_v \\times d_q}$,=\n",
        "  - must select **attention dimensionality** $d_v$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Learning the query vector\n"
      ],
      "metadata": {
        "id": "-CO_vzVSxM5T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U5eWZbfvHc9"
      },
      "source": [
        "\n",
        "\n",
        "But wait, we don't know what $\\mathbf{q}$ should be!\n",
        "\n",
        "We'll have to learn it.\n",
        "\n",
        "$\\mathbf{s_i} = \\mathrm{tanh}(W_s \\cdot \\mathbf{h}_i) \\in \\mathbb{R}~~~~~~~~~ W_s \\in \\mathbb{R^{d_h}}$\n",
        "\n",
        "$\\alpha = \\mathrm{softmax}({\\mathbf{s}})$\n",
        "\n",
        "$\\mathbf{a} = \\sum_i^n \\alpha_i \\mathbf{h}_i \\in \\mathbb{R}^{d_h}$\n",
        "\n",
        "$y = \\mathrm{softmax}(W_y \\cdot \\mathbf{a})$\n",
        "<br><br>\n",
        "\n",
        "\n",
        "![figs/lstmclf4.png](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/lstmclf4.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Attention for Language Models"
      ],
      "metadata": {
        "id": "ioD31_UvxUbm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnX9hjiXvHc9"
      },
      "source": [
        "\n",
        "\n",
        "- LSTMs go through a lot of trouble to enable long-range dependencies\n",
        "\n",
        "- What if we just let every word in a sentence influence every other word ?!\n",
        "\n",
        "\n",
        "![figs/selfatt1.png](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/selfatt1.png?raw=1)\n",
        "\n",
        "We can use attention to determine which other words are important to predict the next word $t$.\n",
        "\n",
        "$$h_t =  \\sum_{i\\ne t}^n \\alpha_i \\mathbf{h}_i$$\n",
        "\n",
        "\n",
        "Is this scalable?\n",
        "\n",
        "<br><br>\n",
        "\n",
        "\n",
        "By removing sequential dependencies, we can compute embeddings in parallel for each sentence.\n",
        "- In complexity speak, we've increased the Work but decreased the Span, so it is more parallelizable\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention-based word representations"
      ],
      "metadata": {
        "id": "nF36atMHxfZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "By applying attention to each token in the input, we compute hidden representations $h_i$ for each input work.\n",
        "- Each $h_i$ depends on all the other words in the input.\n",
        "\n",
        "\n",
        "$$\\mathbf{v}_j = V\\mathbf{x_j} ~~~V\\in \\mathbb{R}^{dxd} ~~~$$ **values for node j**\n",
        "\n",
        "$$\\mathbf{k}_j = K \\mathbf{x}_j ~~~K\\in \\mathbb{R}^{dxd} ~~~$$ **keys for node j**\n",
        "\n",
        "$$\\mathbf{q}_i = Q\\mathbf{x_i}~~~$$ **query for node i**\n",
        "\n",
        "$$\\alpha_{ij} = \\frac{\\exp(\\mathbf{q}_i \\cdot \\mathbf{k}_j)}{\\sum_{j'} \\exp({\\mathbf{q}_i \\cdot \\mathbf{k}_{j'})}} ~~~$$ **affinities between node i and j**\n",
        "\n",
        "$$\\mathbf{h}_i = \\sum_{j=1}^n \\alpha_{ij} \\mathbf{v}_j$$\n",
        "\n",
        "\n",
        "$\\mathbf{h}_i$ is the contextual representation of input $\\mathbf{x}_i$.  $\\alpha_{ij}$ controls the strength of each contribution from $v_j$.\n",
        "\n",
        "<br>\n",
        "\n",
        "This tells us **what information from what other tokens, should be used in representing** $\\mathbf{x}_i$.\n",
        "\n",
        "\n",
        "The matrices $K$, $Q$, $V$ allow us to use different views of each $\\mathbf{x}_i$ for the different roles of key, query, and value.\n",
        "\n",
        "<br>\n",
        "\n",
        "<br><br><br>\n",
        "\n",
        "<img src=\"https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/selfattention.png?raw=1\" width=60%/>\n",
        "\n",
        "[source](https://web.stanford.edu/class/cs224n/readings/cs224n-self-attention-transformers-2023_draft.pdf)\n",
        "\n"
      ],
      "metadata": {
        "id": "PqtqWcopxcLM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Position"
      ],
      "metadata": {
        "id": "zygxcHKayDIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "But wait, the above approach completely ignores word order!!\n",
        "\n",
        "<br><br><br>\n",
        "\n",
        "**Idea**: explicitly add the position of a word in its representation.\n",
        "\n",
        "- E.g., we can represent a binary string $p$ encoding the position of a word; e.g. $000, 001, 010, 011,... 111$ for sequences up to length 8.\n",
        "\n",
        "\n",
        "- Then, we can represent each input embedding $h_i$ as the concatenation $h_i \\oplus p_i$ or alternatively as the sum $h_i + p_i$.\n",
        "\n",
        "\n",
        "- We can also get more fancy and learn an embedding for $p_i$.\n",
        "  - requires picking a maximum sentence length\n",
        "  - most common approach\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8couM3aMyBFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Simple attention example"
      ],
      "metadata": {
        "id": "5S24YoMLzJXl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tXyJIH8vHc-"
      },
      "source": [
        "\n",
        "\n",
        "Let's walk through a simple example of an attention model for binary classification.\n",
        "\n",
        "We'll assume there are three words in the world: $a,b,c$. We will assume that $a$ and $b$ matter for the classification, but $c$ doesn't.\n",
        "\n",
        "We want to see if the attention weights will \"pay attention to\" $a$ and $b$ and not $c$.\n",
        "\n",
        "\n",
        "Below is a simple implementation of attention where we assume:\n",
        "- There is no embedding layer; so, we just use the `x` input vectors directly instead of `h`.\n",
        "- We are doing binary classification, so we use Sigmoid instead of Softmax.\n",
        "\n",
        "This would represent a problem where we want to classify a document into one of two classes, using the raw one-hot encoding of each word as input.\n",
        "\n",
        "$\\mathbf{s_i} = \\mathrm{tanh}(W_s \\cdot \\mathbf{x}_i) \\in \\mathbb{R}~~~~~~~~~ W_s \\in \\mathbb{R^{d_x}}$\n",
        "\n",
        "$\\alpha = \\mathrm{softmax}({\\mathbf{s}})$\n",
        "\n",
        "$\\mathbf{a} = \\sum_i^n \\alpha_i \\mathbf{x}_i \\in \\mathbb{R}^{d_x}$\n",
        "\n",
        "$ y = \\mathrm{sigmoid}(W_y \\cdot \\mathbf{a}) $\n",
        "\n",
        "<img src=\"https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/lstmclf4.png?raw=1\" width=\"40%\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qs5taqB7vHc-"
      },
      "outputs": [],
      "source": [
        "# Let's package these computations up inside of an nn.Module so we can learn W_s and W_y.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleAttention(nn.Module):\n",
        "    def __init__(self, input_size, verbose=False):\n",
        "        super(SimpleAttention, self).__init__()\n",
        "        # Since we don't know what the output size will be (the number of tokens), we can't use nn.Linear:\n",
        "        # self.input_to_attention = nn.Linear(input_size, output_size=??, bias=False)\n",
        "        # Instead, we'll just use the Parameter object, which is a trainable tensor.\n",
        "        self.W_s = nn.Parameter(torch.randn(input_size, dtype=torch.float64))\n",
        "\n",
        "        # W_y: hidden to prediction\n",
        "        self.W_y = nn.Linear(input_size, 1, bias=False, dtype=torch.float64)\n",
        "\n",
        "        self.verbose = verbose\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax(dim=0)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # \"@\" is the matrix multiply operator\n",
        "        # This computes s = tanh(x * W_s) for all tokens at the same time.\n",
        "        s = self.tanh(x @ self.W_s)\n",
        "        # normalize using softmax\n",
        "        alpha = self.softmax(s)\n",
        "        # compute final combined embeddings\n",
        "        a = alpha @ x\n",
        "        # classify\n",
        "        y = self.sigmoid(self.W_y(a))\n",
        "        if self.verbose:\n",
        "            print('s=\\n', s)\n",
        "            print('alpha=\\n', alpha)\n",
        "            print('a=\\n', a)\n",
        "            print('y=\\n', y)\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ8ONzyFvHc_"
      },
      "source": [
        "Let's make some fake data where the input vocabulary `['a', 'b', 'c']`. Generate data such that:\n",
        "- Documents with `a` are likely to be positive.\n",
        "- Documents with `b` are likely to be negative.\n",
        "- Documents with `c` are equally likely to be positive or negative.\n",
        "\n",
        "So, we would expect our attention layer to pay attention to words `a` and `b` but ignore `c`.\n",
        "\n",
        "And, we expect the classification layer to have large positive weights for `a` and large negative weights for `b`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q2a5yEAWvHc_",
        "outputId": "cec3fac6-adef-4af2-99dc-abbeb982687d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [0., 0., 1.],\n",
              "        [1., 0., 0.],\n",
              "        [0., 0., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# 1-hot encodings of the \"words\" a,b,c\n",
        "a = [1,0,0]\n",
        "b = [0,1,0]\n",
        "c = [0,0,1]\n",
        "\n",
        "# e.g., the document containing a, c, a, c\n",
        "torch.tensor([a,c,a,c], dtype=torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "weCXEj9QvHc_",
        "outputId": "713619f6-871d-40c2-b926-b660cc28c407",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s=\n",
            " tensor([-0.2254,  0.7672, -0.2254,  0.7672], dtype=torch.float64,\n",
            "       grad_fn=<TanhBackward0>)\n",
            "alpha=\n",
            " tensor([0.1352, 0.3648, 0.1352, 0.3648], dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "a=\n",
            " tensor([0.2704, 0.0000, 0.7296], dtype=torch.float64,\n",
            "       grad_fn=<SqueezeBackward4>)\n",
            "y=\n",
            " tensor([0.3896], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3896], dtype=torch.float64, grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "model = SimpleAttention(input_size=3, verbose=True)\n",
        "model(torch.tensor([a,c,a,c], dtype=torch.float64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eVoJJZs_vHc_",
        "outputId": "9f3b7d74-e496-4867-b8f5-2f0f66341930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 0., 0.],\n",
            "         [0., 0., 1.],\n",
            "         [1., 0., 0.],\n",
            "         [0., 0., 1.]]], dtype=torch.float64)\n",
            "tensor(1., dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# create training instances where\n",
        "# a -> label=1\n",
        "# b -> label=0\n",
        "# c -> label=random\n",
        "X = []\n",
        "y = []\n",
        "for _ in range(10):\n",
        "    X.append(torch.tensor([a,c,a,c], dtype=torch.float64))\n",
        "    y.append(1)\n",
        "\n",
        "for _ in range(10):\n",
        "    X.append(torch.tensor([b,c,b,c], dtype=torch.float64))\n",
        "    y.append(0)\n",
        "X = torch.stack(X)\n",
        "# print first training instance\n",
        "print(X[:1])\n",
        "y = torch.tensor(y, dtype=torch.float64)\n",
        "# print first label\n",
        "print(y[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4GTwVXykvHc_"
      },
      "outputs": [],
      "source": [
        "data = list(zip(X,y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UGrPWF2CvHc_",
        "outputId": "6a34cdf7-4c49-46d2-f563-31db09653137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 50.25it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleAttention(\n",
              "  (W_y): Linear(in_features=3, out_features=1, bias=False)\n",
              "  (tanh): Tanh()\n",
              "  (softmax): Softmax(dim=0)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_model(model, data, epochs=20, learning_rate=0.4):\n",
        "    torch.random.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(),\n",
        "                                 lr=learning_rate)\n",
        "    model.verbose = False\n",
        "    loss_val = []\n",
        "    # main training loop\n",
        "    for epoch in tqdm(range(epochs), total=epochs):\n",
        "        np.random.shuffle(data)\n",
        "        optimizer.zero_grad() # reset all the gradient information\n",
        "        for X, y in data:\n",
        "            result = model.forward(X)\n",
        "            loss = criterion(result[0], y)\n",
        "            loss.backward()      # computes all the gradients\n",
        "        optimizer.step()     # update parameters\n",
        "        loss_val.append(loss.item())\n",
        "    plt.figure()\n",
        "    plt.plot(loss_val, 'bo-')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('instances')\n",
        "    plt.show()\n",
        "    return model\n",
        "\n",
        "\n",
        "att = SimpleAttention(input_size=3)\n",
        "train_model(att, data, learning_rate=.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3h54hFFuvHdA",
        "outputId": "1be95702-cdb2-47e0-8152-149390b43985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input=\n",
            " tensor([[1., 0., 0.],\n",
            "        [0., 0., 1.],\n",
            "        [1., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64)\n",
            "s=\n",
            " tensor([ 0.9973, -0.9991,  0.9973, -0.9991], dtype=torch.float64,\n",
            "       grad_fn=<TanhBackward0>)\n",
            "alpha=\n",
            " tensor([0.4402, 0.0598, 0.4402, 0.0598], dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "a=\n",
            " tensor([0.8804, 0.0000, 0.1196], dtype=torch.float64,\n",
            "       grad_fn=<SqueezeBackward4>)\n",
            "y=\n",
            " tensor([0.9969], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9969], dtype=torch.float64, grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "att.verbose=True\n",
        "# input is a,c,a,c\n",
        "print('input=\\n', X[0])\n",
        "att.forward(X[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XbDtj-ZFvHdA",
        "outputId": "67eb7982-5e22-4168-ea7f-367e0edd4d39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([ 3.3035,  4.1346, -3.8337], dtype=torch.float64, requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "att.W_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "X5yneEkkvHdA",
        "outputId": "e92e7809-061e-426e-85bc-2792f9cf37e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 6.1794, -6.1569,  2.9181]], dtype=torch.float64, requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "att.W_y.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SH2K0nUovHdA",
        "outputId": "ec6cf25b-5536-4242-ac3f-c13f13f4515a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s=\n",
            " tensor([ 0.9973, -0.9991,  0.9973, -0.9991,  0.9973, -0.9991,  0.9973, -0.9991,\n",
            "         0.9973, -0.9991], dtype=torch.float64, grad_fn=<TanhBackward0>)\n",
            "alpha=\n",
            " tensor([0.1761, 0.0239, 0.1761, 0.0239, 0.1761, 0.0239, 0.1761, 0.0239, 0.1761,\n",
            "        0.0239], dtype=torch.float64, grad_fn=<SoftmaxBackward0>)\n",
            "a=\n",
            " tensor([0.8804, 0.0000, 0.1196], dtype=torch.float64,\n",
            "       grad_fn=<SqueezeBackward4>)\n",
            "y=\n",
            " tensor([0.9969], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9969], dtype=torch.float64, grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "att.forward(torch.tensor([a,c,a,c,a,c,a,c,a,c], dtype=torch.float64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aeLs3Qg2vHdA",
        "outputId": "8297b67a-b6c9-4256-9edb-2bb8b63c7043",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s=\n",
            " tensor([0.9973, 0.9995], dtype=torch.float64, grad_fn=<TanhBackward0>)\n",
            "alpha=\n",
            " tensor([0.4995, 0.5005], dtype=torch.float64, grad_fn=<SoftmaxBackward0>)\n",
            "a=\n",
            " tensor([0.4995, 0.5005, 0.0000], dtype=torch.float64,\n",
            "       grad_fn=<SqueezeBackward4>)\n",
            "y=\n",
            " tensor([0.5011], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5011], dtype=torch.float64, grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "att.forward(torch.tensor([a,b], dtype=torch.float64))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Group Task\n"
      ],
      "metadata": {
        "id": "ABbCoBSi1v4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the `SimpleAttention` implementation above to use sigmoid instead of softmax to compute the `alpha` values. How does this affect the `alpha` values in the subsequent example? Why do you think this is? Is this good or bad?"
      ],
      "metadata": {
        "id": "lBcU9GjN112E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1YwQFKzvHdB"
      },
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Sources\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- https://web.stanford.edu/class/cs224n/"
      ],
      "metadata": {
        "id": "-MRdAc_O01gu"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f8OiXeEVwfGw",
        "04LxYCDQvHc8",
        "jO4DP-kjwwFG",
        "14jFC71cwyqX",
        "kapVP3M5xCIZ",
        "-CO_vzVSxM5T",
        "ioD31_UvxUbm",
        "5S24YoMLzJXl",
        "ABbCoBSi1v4r",
        "V1YwQFKzvHdB"
      ],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}