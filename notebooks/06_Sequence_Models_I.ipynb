{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Tulane](https://github.com/tulane-cmps6730/main/blob/main/img/banner.png?raw=true)\n",
        "\n",
        "<center>\n",
        "\n",
        "<font size=\"+3\">Sequence Models I</font>\n",
        "\n",
        "[Aron Culotta](https://cs.tulane.edu/~aculotta/)  \n",
        "[Tulane University](https://cs.tulane.edu/)\n",
        "\n",
        "<a href=\"http://colab.research.google.com/github/tulane-cmps6730/main/blob/main/notebooks/06_Sequence_Models_I.ipynb\">\n",
        "        <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Google_Colaboratory_SVG_Logo.svg/320px-Google_Colaboratory_SVG_Logo.svg.png\"  width=10%/></a>\n",
        "<a href=\"https://github.com/tulane-cmps6730/main/tree/main\">\n",
        "        <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/GitHub_Invertocat_Logo.svg/240px-GitHub_Invertocat_Logo.svg.png\" width=6%/></a>\n",
        "\n",
        "In this module, we'll learn about models that better capture the structure of languages, including sequences and trees.\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "KGuBxBXc7uM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Sequence Classification"
      ],
      "metadata": {
        "id": "Mm3ZGl518avu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "D8_aODrx7uM9"
      },
      "source": [
        "Classification assumes each input has a single output label:\n",
        "\n",
        "- **input:** email\n",
        "- **output:** spam or not\n",
        "\n",
        "\n",
        "However, for many language processing tasks, the output is a sequence of labels.\n",
        "\n",
        "Examples include:\n",
        "\n",
        "\n",
        "- Part-of-speech tagging:\n",
        "\n",
        "| Det | N   | V      | P    | D   | N    |\n",
        "|-----|-----|--------|------|-----|------|\n",
        "| The | cow | jumped | over | the | moon. |\n",
        "\n",
        "\n",
        "- Named-entity recognition\n",
        "\n",
        "| Person    | Person|  _     | _    | Location  | _    |\n",
        "|-----------|-------|--------|------|-----------|------|\n",
        "| President | Trump | flew   | to   | D.C.      | today. |\n",
        "\n",
        "- Speech recognition\n",
        "\n",
        "| \"hu\"      | \"ow\" |  \"ah\"  | \"r\"  | \"ye\"      | \"ooh\"    |\n",
        "|-----------|------|--------|------|-----------|----------|\n",
        "|-----------|------|--------|------|-----------|----------|\n",
        "\n",
        "<img src='https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/audio.jpg?raw=1' width=50%/>\n",
        "\n",
        "<br>\n",
        "\n",
        "All of the above examples have a sequence of input symbols (e.g., words) and a sequence of output symbols (e.g., parts-of-speech).\n",
        "\n",
        "<br><br><br>\n",
        "Over the next two modules, we will consider different models that support sequence predictions. Much like we did with classification, we'll first begin with traditional, statistical approaches that look a lot like Naive Bayes and n-gram language models. Then, we will proceed to neural network versions of these ideas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Hidden Markov Models"
      ],
      "metadata": {
        "id": "64OnzvbK9UHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Hidden Markov Models (HMMs) are probabilistic models of sequences of input variables and output variables. They were used widely in the 1980s-2000s, initially for speech recognition systems.\n",
        "\n",
        "They can be viewed similarly to n-gram language models, but whereas language models assume all variables are observable, HMMs extend to sequences of output variables that are not observerd.\n",
        "\n",
        "The output at time $i$ depends on the input at time $i$ and the output at previous times $i-1$, $i-2$, ...:\n",
        "\n",
        "- **Language model**: $p(w_i|w_{i-2}, w_{i-1})$\n",
        "- **Hidden Markov model**: $p(y_i|w_i, y_{i-1}, y_{i-2}, \\ldots)$\n",
        "  - e.g., $y_i$ is part-of-speech tag at time $i$\n",
        "\n",
        "<br><br><br>"
      ],
      "metadata": {
        "id": "W4BejKUy9XdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Markov chain"
      ],
      "metadata": {
        "id": "OQZmpqAf-Cnt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UruZyMnm7uM9"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "To begin, let's consider an **observed** Markov chain.\n",
        "\n",
        "The language models we saw previously are  examples of this.  \n",
        "E.g, bigram language model assumes next word is independent of all other words given the previous word:\n",
        "\n",
        "$$p(w_i \\mid w_{i-n} \\ldots w_{i-1}) \\triangleq p(w_i \\mid w_{i-1})$$\n",
        "\n",
        "This is a **first-order Markov assumption**. We can draw this model as a **weighted** finite state machine.\n",
        "\n",
        "E.g., assume our language model only has three words  \n",
        "{\"snow\", \"white\", \"is\"}:\n",
        "\n",
        "![snow](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/snow.png?raw=1)\n",
        "\n",
        "- $p($is $ \\mid $ snow, white$)  \\triangleq   p($ is $ \\mid $ snow$) = a_{21}$\n",
        "- Each edge is weighted by a conditional probability.\n",
        "\n",
        "\n",
        "<br><br>\n",
        "\n",
        "A Markov chain consists of the following:\n",
        "\n",
        "- $Q=q_1 \\ldots q_N$, a set of $N$ **states**\n",
        "- $A = a_{01}a_{02} \\ldots a_{n1} \\ldots a_{nn}$, a **transition probability matrix**.\n",
        "  - Each $a_{ij}=p(s_j | s_i)$ is the probability of the transition from state $i$ to state $j$\n",
        "  - All transitions from a state must sum to 1: $\\sum_{j=1}^n a_{ij} = 1 $ $\\forall i$\n",
        "- $q_0$: start state\n",
        "- $q_F$: end (final) state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequence probabilities"
      ],
      "metadata": {
        "id": "nVD3jy5P-Xne"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPVej7Po7uM-"
      },
      "source": [
        "\n",
        "**A Markov chain assigns a probability to a sequence of words:**\n",
        "- Equal to the product of the probabilities for an accepting path\n",
        "  - If multiple accepting paths, equal to the largest value for any path\n",
        "  \n",
        "  \n",
        "\n",
        "![snow](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/snow.png?raw=1)\n",
        "\n",
        "$p($\"snow white is\"$)$    \n",
        "$= p($snow $\\mid q_0) * p($ white $\\mid $ snow$ ) * p($ is $\\mid $ white$) * p(q_F \\mid $ is $)$  \n",
        "$= a_{02} * a_{23} * a_{31} * a_{14}$\n",
        "\n",
        "\n",
        "**\"Unrolled\" chain**\n",
        "\n",
        "![snow_unrolled](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/snow_unrolled.png?raw=1)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From Observed to Hidden Markov Chains"
      ],
      "metadata": {
        "id": "QtQub9mM-ejU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tcw4CT1i7uM-"
      },
      "source": [
        "\n",
        "\n",
        "- A Markov chain over **unobserved** (\"hidden\") variables\n",
        "\n",
        "![pos](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/pos.png?raw=1)\n",
        "\n",
        "![pos_u](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/pos_unrolled.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example: weather inference"
      ],
      "metadata": {
        "id": "58uRVDlI-na3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J88s1LT7uM-"
      },
      "source": [
        "\n",
        "\n",
        "- Future climatologist wants to know:\n",
        "  - What was the weather like in New Orleans in March 2024?\n",
        "- We do not have records of temperature, but we luckily I kept records of the number of ice creams I ate each day.\n",
        "\n",
        "**Problem:**\n",
        "\n",
        "- Given a sequence of observations $O$\n",
        "  - ints representing number of ice creams I ate per day\n",
        "- Predict the hidden sequence $Q$ of weather states\n",
        "  - \"H\" for Hot or \"C\" for Cold\n",
        "  \n",
        "![icecream](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/icecream.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formal Definition of HMMs"
      ],
      "metadata": {
        "id": "WCpiSJJx-x7J"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koQPT9ev7uM-"
      },
      "source": [
        "\n",
        "\n",
        "A Hidden Markov Model consists of the following:\n",
        "\n",
        "- $Q=q_1 \\ldots q_n$, a set of $n$ **states**\n",
        "- $A = a_{01}a_{02} \\ldots a_{n1} \\ldots a_{nn}$, a **transition probability matrix**.\n",
        "  - Each $a_{ij}=p(s_j | s_i)$ is the probability of the transition from state $i$ to state $j$\n",
        "  - All transitions from a state must sum to 1: $\\sum_{j=1}^n a_{ij} = 1 $ $\\forall i$\n",
        "- $O = o_1 \\ldots o_T$, a sequence of $T$ **observations**\n",
        "  - Each is drawn from vocabulary $V = v_1 \\ldots v_V$\n",
        "- $B = b_i(o_i)$, a sequence of **observation likelihoods**, aka **emission probabilities**\n",
        "  - The probability of observation $o_i$ being generated by state $i$\n",
        "  - $p(o_i|q_i)$\n",
        "- $q_0$: start state and $q_F$: end (final) state\n",
        "  - Neither is associated with observations\n",
        "  - Each has transition probabilities for states:\n",
        "    - $a_{01} \\ldots a_{0n}$ for start transitions\n",
        "    - $a_{1F} \\ldots a_{nF}$ for end transitions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HMM Assumptions\n"
      ],
      "metadata": {
        "id": "VgGxOni829EU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2BY6qnH7uM_"
      },
      "source": [
        "\n",
        "1. **Markov assumption**:\n",
        "  - $p(q_i \\mid q_1 \\ldots q_{i-1}) \\triangleq p(q_i \\mid q_{i-1})$  \n",
        "<br><br>\n",
        "2. **Output independence**:\n",
        "  - $p(o_i \\mid q_1 \\ldots q_i \\ldots q_T, o_1 \\ldots o_i \\ldots o_T) \\triangleq p(o_i \\mid q_i)$\n",
        "  \n",
        "  \n",
        "<br><br>\n",
        "Why make these assumptions?\n",
        "\n",
        "\n",
        "<br><br><br>\n",
        "\n",
        "HMMs may be:\n",
        "- **fully connected** (\"ergodic\"): every state is reachable from every other state\n",
        "- or not: e.g., illegal to transition from \"of\" to present tense verb (\"of jump\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Three Fundamental Problems of HMMs"
      ],
      "metadata": {
        "id": "gbKWyIly-9DO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLC-I4er7uM_"
      },
      "source": [
        "\n",
        "\n",
        "1. **Likelihood:**\n",
        "  - Given an HMM $\\lambda = (A,B)$ and an observation sequence $O$\n",
        "  - Compute the likelihood $p(O \\mid \\lambda)$.\n",
        "  - I.e., what is the probability of this observation sequence given this HMM?\n",
        "<br><br><br>  \n",
        "2. **Decoding:**\n",
        "  - Given an observation sequence $O$ and an HMM $\\lambda=(A,B)$\n",
        "  - Find the most probable sequence $Q$\n",
        "<br><br><br>\n",
        "3. **Learning:**\n",
        "  - Given an observation sequence $O$ and the set of states in the HMM\n",
        "  - Learn the HMM parameters $A$ and $B$.\n",
        "  \n",
        "<br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Computing Likelihood with the Forward Algorithm"
      ],
      "metadata": {
        "id": "uWneomoL_G1Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ufeJNQX7uM_"
      },
      "source": [
        "\n",
        "\n",
        " Given an HMM $\\lambda = (A,B)$ and an observation sequence $O$\n",
        "  - Compute the likelihood $p(O \\mid \\lambda)$.\n",
        "  - I.e., what is the probability of this observation sequence given this HMM?\n",
        "  \n",
        "<br><br>\n",
        "Recall how we computed the likelihood of an *observed* sequence in a **Markov chain**\n",
        "- Just multiply transition probabilities\n",
        "\n",
        "$p($\"snow white is\"$)$    \n",
        "$= p($snow $\\mid q_0) * p($ white $\\mid $ snow$ ) * p($ is $\\mid $ white$) * p(q_F \\mid $ is $)$  \n",
        "$= a_{02} * a_{23} * a_{31} * a_{14}$\n",
        "\n",
        "![snow_unrolled](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/snow_unrolled.png?raw=1)\n",
        "\n",
        "<br><br>\n",
        "\n",
        "**Why doesn't this work for HMMs?**\n",
        "\n",
        "![pos_u](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/pos_unrolled.png?raw=1)\n",
        "\n",
        "<br><br><br>\n",
        "We don't observe the hidden states!\n",
        "\n",
        "<br><br>\n",
        "Let's start with a simpler problem:\n",
        "- Assume we know the hidden states for this observation sequence\n",
        "- E.g., in ice cream example\n",
        "  - I ate {3, 1, 3} ice creams\n",
        "  - The weather was {hot, hot, cold}\n",
        "  - $O=\\{3,1,3\\}$\n",
        "  - $Q = \\{H, H, C\\}$\n",
        "  \n",
        "<br><br>\n",
        "We can compute probability as:\n",
        "\n",
        "$$\n",
        "p(O|Q) = \\prod_i^T p(o_i \\mid q_i)\n",
        "$$\n",
        "\n",
        "$$p(\\{3, 1, 3\\} \\mid \\{H, H, C\\}) = p(3 \\mid H) * p(1 \\mid H) * p(3 \\mid C)$$  \n",
        "$$= .4 * .2 * .1 $$\n",
        "\n",
        "![l1](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/likelihood1.png?raw=1)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "Since we don't know the true weather state sequence, we will sum over all possible state sequences, weighted by probability.\n",
        "\n",
        "First, note that the joint probability $p(O,Q)$ just multiplies all the transitions $A$ and $B$:\n",
        "$$\n",
        "p(O, Q) = p(O \\mid Q) \\times p(Q) = \\prod_i^T p(o_i \\mid q_i) \\times \\prod_i^T p(q_i \\mid q_{i-1})\n",
        "$$\n",
        "\n",
        "![icj](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/icecream_joint.png?raw=1)\n",
        "\n",
        "To compute $p(O)$ from $p(O, Q)$, recall the notion of *marginalization* in probability:\n",
        "\n",
        "$$p(x=x_j) = \\sum_{y_i} p(x=x_j,y=y_i)$$  \n",
        "\n",
        "E.g., if $x=1$ means a student passed test 1, and $y=1$ means a student passed test 2,  \n",
        "then the probability that a student passes test 1 is:\n",
        "\n",
        "$$\n",
        "p(x=1) = p(x=1,y=0) + p(x=1,y=1)\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "We will use marginalization to sum over possible state sequences, to compute the probability of the observation sequence.\n",
        "\n",
        "$$\n",
        "p(O) = \\sum_Q p(O, Q) = \\sum_Q p(O \\mid Q) p(Q)\n",
        "$$\n",
        "- last step by chain rule: $p(X,Y) = p(X \\mid Y) p(Y)$  \n",
        "\n",
        "\n",
        "<br>\n",
        "Back to the ice cream example:\n",
        "\n",
        "$$ p(\\{3, 1, 3\\}) = p(\\{3, 1, 3\\}, \\{C, C, C\\}) + p(\\{3, 1, 3\\}, \\{C, C, H\\}) + \\ldots $$  \n",
        "$$ + p(\\{3, 1, 3\\}, \\{H, H, C\\}) + p(\\{3, 1, 3\\}, \\{H, H, H\\}) $$\n",
        "\n",
        "\n",
        "**Problem with this approach**: If we have $N$ states and $T$ observations, how many possible hidden sequences must we sum over?\n",
        "\n",
        "<br><br><br><br>\n",
        "$$N^T$$\n",
        "\n",
        "<br><br><br>\n",
        "Is there a polynomial time algorithm?\n",
        "<br><br>\n",
        "Yes: Dynamic programming to the rescue.\n",
        "- There is a lot of duplicate work in the summation above.\n",
        "- We will store intermediate values as we scan the input from left to right.\n",
        "<br><br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGD9pfTA7uNA"
      },
      "source": [
        "#### Forward algorithm\n",
        "\n",
        "##### Forward Trellis\n",
        "Stores observation probabilities up to time step $t$\n",
        "\n",
        "- $\\alpha_t(j)=$ the probability of being in state $j$ after seeing the first $t$ observations  \n",
        "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$=p(o_1\\ldots o_t, q_t=j \\mid \\lambda) = \\sum_{i=1}^N \\alpha_{t-1}(i)a_{ij}b_j(o_t)$\n",
        "  - $\\alpha_{t-1}(i)$ the previous forward path probability\n",
        "  - $a_{ij}$ the transition probability from previous state $i$ to current state $j$\n",
        "  - $b_j(o_t)$ the likelihood of the observation at time $t$ $p(o_t \\mid q_j$)\n",
        "<br><br>\n",
        "- E.g., $\\alpha_2(H)$ computes forward probability of being in state H at time 2 having generated the partial observation $\\{3, 1\\}$\n",
        "  - Generate two next steps:\n",
        "    - $\\alpha_1(H) \\times p(H \\mid H) \\times p(1 \\mid H)$ (if previous state was $H$)\n",
        "    - $\\alpha_1(C) \\times p(H \\mid C) \\times p(1 \\mid H)$ (if previous state was $C$)\n",
        "    \n",
        "![trellis](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/trellis.png?raw=1)\n",
        "\n",
        "\n",
        "##### Recursive definition\n",
        "\n",
        "1. Initialization:\n",
        "  - $\\alpha_1(j) = a_{0j}b_j(o_j) $ &nbsp; $1 \\le j \\le N$\n",
        "  - probabilities of starting in state $j$ and emitting observation $o_1$\n",
        "<br><br>\n",
        "2. Recursion\n",
        "  - $\\alpha_t(j) = \\sum_{i=1}^N \\alpha_{t-1}(i)a_{ij}b_j(o_t) $ &nbsp;&nbsp;$ 1 \\le j \\le N, 1 < t < T$\n",
        "  - the probability of being in state $j$ after seeing the first $t$ observations\n",
        "  - sums over all possible states we could have been in at time step $t-1$\n",
        "<br><br>\n",
        "3. Termination\n",
        "  - $ p(O \\mid \\lambda) = \\alpha_T(q_F) = \\sum_{i=1}^N \\alpha_T(i)a_{iF}$\n",
        "  \n",
        "![trellis2](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/trellis2.png?raw=1)\n",
        "\n",
        "#### Pseudocode\n",
        "\n",
        "![code](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/forward_code.png?raw=1)\n",
        "\n",
        "**Runtime?**\n",
        "<br><br><br><br>\n",
        "$$O(N^2T) << O(N^T)$$\n",
        "\n",
        "<br><br><br><br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Decoding with the Viterbi algorithm"
      ],
      "metadata": {
        "id": "xq5e1V_J_Ytf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP5SRU-o7uNA"
      },
      "source": [
        "\n",
        "  - Given an observation sequence $O$ and an HMM $\\lambda=(A,B)$\n",
        "  - Find the most probable sequence $Q$\n",
        "  - E.g., given the ice cream observations $\\{3, 1, 3\\}$, what is the most likely temperature sequence?\n",
        "  \n",
        "  \n",
        "**Naive approach:**  \n",
        "- Run the forward algorithm for each possible state sequence\n",
        "- Return the state sequence that maximizes $p(O \\mid \\lambda)$\n",
        "- Still exponential: $O(N^T)$\n",
        "\n",
        "**Efficient approach:**\n",
        "\n",
        "#### Viterbi algorithm\n",
        "\n",
        "A dynamic program, similar to the forward algorithm, to find best path through the trellis.\n",
        "\n",
        "![viterbi](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/viterbi.png?raw=1)\n",
        "\n",
        "$$v_t(j) = \\max_{q_0 \\ldots q_{t-1}}p(q_0\\ldots q_{t-1}, o_1 \\ldots o_t, q_t = j \\mid \\lambda)$$  \n",
        "$$ = \\max_{i=1}^N v_{t-1}(i)a_{ij}b_j(o_t)$$\n",
        "- $v_{t-1}(i)$: the previous Viterbi path probability from the prior time step\n",
        "- $a_{ij}$: the transition probability from prior state $q_i$ to current state $q_j$\n",
        "- $b_j(o_t)$: the probability of the observation at time $t$: $p(o_t \\mid q_t)$\n",
        "\n",
        "Contrast with the forward algorithm: $\\alpha_t(j)=\\sum_{i=1}^N \\alpha_{t-1}a_{ij}b_j(o_t)$  \n",
        "Two differences:\n",
        " - sum becomes $\\max$\n",
        " - Also need additional bookkeeping to store the best path itself, rather than just the probability.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##### Pseudocode\n",
        "\n",
        "![vit_code](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/viterbi_code.png?raw=1)\n",
        "\n",
        "##### Recursive definition\n",
        "\n",
        "1. Initialization:\n",
        "  - $v_1(j) = a_{0j}b_j(o_j) $ &nbsp; $1 \\le j \\le N$\n",
        "    - probabilities of starting in state $j$ and emitting observation $o_1$\n",
        "  - $bt_1(j) = 0$ back trace to store best path\n",
        "<br><br>\n",
        "2. Recursion\n",
        "  - $v_t(j) = \\max_{i=1}^N v_{t-1}(i)a_{ij}b_j(o_t) $ &nbsp;&nbsp;$ 1 \\le j \\le N, 1 < t < T$\n",
        "    - the probability of the best path continuing to state $j$ after seeing the first $t$ observations\n",
        "  - $bt_t(j) = argmax_{i=1}^N v_{t-1}(i)a_{ij}b_j(o_t) $ &nbsp;&nbsp;$ 1 \\le j \\le N, 1 < t < T$\n",
        "    - update the best path so far\n",
        "<br><br>\n",
        "3. Termination\n",
        "  - $ P^* = v_T(q_F) = \\max_{i=1}^N v_T(i)a_{iF}$\n",
        "    - the best score\n",
        "  - $q_T^* = bt_T(q_F) = argmax_{i=1}^N v_T(i) * a_{iF}$\n",
        "    - the start of the backtrace (the best second to last state)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Learning\n",
        "\n"
      ],
      "metadata": {
        "id": "OhlCYTK5_61_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This uses the simple \"counting\" estimation we used for language models and naive Bayes\n",
        "\n"
      ],
      "metadata": {
        "id": "cjGmG6c7ACdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transition probabilities\n",
        "\n",
        "$$p(q_i \\mid q_{i-1}) = \\frac{C(q_{i-1}, q_i)}{C(q_{i-1})}$$\n",
        "\n",
        "E.g., if the labeled training set $D$ has only two sentences:\n",
        "\n",
        "> D &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; N &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; V &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; N  \n",
        "> The &nbsp; dog &nbsp; ate &nbsp; food  \n",
        ">  \n",
        "> D &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; N &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; V &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \n",
        "> A black cat drank\n",
        "\n",
        "Then we compute:\n",
        "\n",
        "$$\n",
        "p(N \\mid D) = \\frac{C(D, N)}{C(D)} = \\frac{1}{2}\n",
        "$$\n",
        "\n",
        "We can again use add-$k$ smoothing, e.g., $k=1$:\n",
        "$$\n",
        "p(N \\mid D) = \\frac{C(D, N) + 1}{C(D) + N*k} = \\frac{1+1}{2 + 4} = \\frac{2}{6}\n",
        "$$\n",
        "- where  $N$ is the number of part of speech tags.\n",
        "\n"
      ],
      "metadata": {
        "id": "dP3ungVDAPRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Emission probabilities\n",
        "\n",
        "We can do the same to estimate the emission probabilities:\n",
        "\n",
        "$$\n",
        "p(o_i \\mid q_i) = \\frac{C(o_i, q_i)}{C(q_i)}\n",
        "$$\n",
        "\n",
        "e.g.\n",
        "\n",
        "$$\n",
        "p(dog \\mid N) = \\frac{C(dog, N)}{C(N)} = \\frac{1}{3}\n",
        "$$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "up5klVQ1ASHq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Start/end transitions\n",
        "\n",
        "We may optionally include probabilities to represent start and end transitions:\n",
        "\n",
        "\n",
        "$$p(q_i \\mid \\mathrm{start} ) = \\frac{C( \\mathrm{start} , q_i)}{C(\\mathrm{start})}$$\n",
        "\n",
        "$$p(q_i \\mid \\mathrm{end}) = \\frac{C(q_i, \\mathrm{end})}{C(\\mathrm{end})}$$\n",
        "\n",
        "e.g.:\n",
        "\n",
        "$$p(\\mathrm{The} \\mid \\mathrm{start}) = \\frac{1}{2}$$\n",
        "\n",
        "\n",
        "<br><br>\n",
        "\n",
        "- Note: when computing smoothed estimate, the start states do not factor into the denominator:\n",
        "\n",
        "$$\n",
        "p(N \\mid D) = \\frac{C(D, N) + k}{C(D) + N*k} = \\frac{1+1}{2 + 4} = \\frac{2}{6}\n",
        "$$\n",
        "\n",
        "\n",
        "$$p(\\mathrm{start} \\mid D) = 0$$\n",
        "\n",
        "<br><br>\n",
        "\n",
        "- Note also: if we do not model end states, then when calculating transition probabilities, we handle the final tag in a sentence differently. E.g.\n",
        "$$p(V \\mid N) = \\frac{C(N, V)}{C(N, *)} = \\frac{2}{2} = 1$$\n",
        "  - where $C(N, *)$ means \"count the number of N tags followed by any other tag\"\n",
        "  - Thus, we ignore the \"N\" tag for \"food\" in the first sentence.\n",
        "  - The reason for this is we need to have $\\sum_i p(q_i \\mid N)=1$.\n",
        "  \n",
        "<br><br><br><br>"
      ],
      "metadata": {
        "id": "ByGLpMQ7AUPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unsupervised HMM Learning\n",
        "\n",
        "We won't cover it here, but there are also methods that estimate HMM parameters in an **unsupervised** way.\n",
        "\n",
        "Input is an *unlabeled training set* $D = \\{\\vec{o}_1, \\ldots \\vec{o}_k\\}$ and the number $n$ indicating the number of HMM states allowed.\n",
        "\n",
        "How can we possibly learn $p(q_i \\mid q_{i-1})$ and $p(o_i \\mid q_i)$ without any data about $q$?\n",
        "\n",
        "Crazy idea:\n",
        "- Initialize the probabilities randomly.\n",
        "- Repeat:\n",
        "  - Predict the labels for all the unlabeled data.\n",
        "  - Re-estimate the probabilities as if the predicted labels were the true labels.\n",
        "  \n",
        "This is called the **EM Algorithm** (Expectation-Maximization). See book (Appendix A) for more details\n"
      ],
      "metadata": {
        "id": "2oIfDJ9SAa-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From Sequences to Trees"
      ],
      "metadata": {
        "id": "BUqPhT28EdyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the above models **sequences** of outputs, we know that language exhibits a hierarhical structure.\n",
        "\n",
        "For example, words can be grouped into phrases:\n",
        "\n",
        "> **Noun phrases**: \"the big house\" or \"a beautiful day\"  \n",
        "> **Adjective phrases**: \"very useful\"  \n",
        "> **Prepositional phrases**: \"on the hill\"  \n",
        "> **Verb phrases**: \"saw the dog\"  \n",
        "\n",
        "<br><br>\n",
        "\n",
        "**Language is recursive**\n",
        "\n",
        "- A sentence has many parts, many of which have subparts, many of which have subparts, ...\n",
        "\n",
        "> I saw the dog with one eye on the hill with the tree by the lake...\n",
        "\n",
        "We need a way to compactly represent this recursion. What data structures do you know of that are great at representing recursion?\n",
        "\n",
        "<br><br><br><br><br>\n",
        "\n",
        "Trees!\n",
        "\n",
        "![figs/parse.png](https://github.com/tulane-cmps6730/main/blob/main/lec/overview/figs/green.png?raw=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "kM4CSFEnEhsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Context Free Grammar (CFG)"
      ],
      "metadata": {
        "id": "stLAk3HEyjnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "A CFG is a set of rules that define a language.\n",
        "\n",
        "\n",
        "Informally:\n",
        "\n",
        "- Set of **rules** or **productions**\n",
        "  - Define how constituents can be grouped\n",
        "- **Lexicon**: list of words and symbols\n",
        "\n",
        "**Example: CFG for Noun Phrases**\n",
        "\n",
        "> NP $\\rightarrow$ Det Nominal  \n",
        "> NP $\\rightarrow$ ProperNoun  \n",
        "> Nominal $\\rightarrow$ Noun | Noun Nominal\n",
        "\n",
        "Rules can be part of a hierarchy:\n",
        "\n",
        "> Det $\\rightarrow$ a  \n",
        "> Det $\\rightarrow$ the  \n",
        "> Noun $\\rightarrow$ flight  \n",
        "\n",
        "- **Terminal** symbols: words in the language (e.g., \"a\", \"flight\")\n",
        "- **Nonterminal** symbols: clusters or generalizations of terminals (e.g., Noun, Nominal, NP)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PwNucqzrF894"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Derivation\n",
        "\n",
        "- A sequence of rule expansions to generate a given string.\n",
        "- This sequence is most commonly shown as a **parse tree**\n",
        "\n",
        "![figs/parse.png](https://github.com/tulane-cmps6730/main/blob/main/lec/parsing/figs/parse.png?raw=1)\n",
        "\n",
        "\n",
        "**Derivation**  \n",
        "1. NP $\\rightarrow$ Det Nom\n",
        "2. Det $\\rightarrow$ a\n",
        "3. Nom $\\rightarrow$  Noun\n",
        "4. Noun $\\rightarrow$ flight\n"
      ],
      "metadata": {
        "id": "7Jsjg_fiGNU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CFGs, Formally\n",
        "\n",
        "A context-free grammar is a four-tuple:\n",
        "\n",
        "1. A set of non-terminal symbols (or 'variables') $N$\n",
        "2. A set of terminal symbols $\\Sigma$ (disjoint from $N$)\n",
        "3. A set of productions $P$ of the form $A \\rightarrow \\alpha$, where\n",
        " - $A \\in N$ is a non-terminal\n",
        " - $\\alpha$ is a string of symbols from the infinite set $(\\Sigma \\cup N)^*$\n",
        "4. A start symbol $S$\n",
        "\n",
        "\n",
        "A string $\\alpha_1$ **derives** a string $\\alpha_m$ if $\\alpha_1$ can be rewritten as $\\alpha_m$ by a series of rule applications from $P$.\n",
        "\n",
        "$$\\alpha_1 \\Rightarrow \\alpha_2,  \\alpha_2 \\Rightarrow \\alpha_3,  \\ldots,  \\alpha_{m-1} \\Rightarrow \\alpha_m$$  \n",
        "\n",
        "Denoted: $\\alpha_1 \\Rightarrow^* \\alpha_m$\n",
        "\n",
        "If $A \\rightarrow \\beta$ is a production in $P$, and $\\alpha$ and $\\gamma$ are strings in $(\\Sigma \\cup N)^*$,\n",
        "- $\\alpha A \\gamma$ **directly derives** $\\alpha \\beta \\gamma$\n",
        "- denoted: $\\alpha A \\gamma \\Rightarrow \\alpha \\beta \\gamma$\n",
        "\n",
        "> a $Noun$ ride $\\Rightarrow$ a train ride (by applying $Noun \\rightarrow train$)"
      ],
      "metadata": {
        "id": "dKYa3uTdGx-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Example: CFG for airline reservation system\n",
        "\n",
        "![figs/lexicon.png](https://github.com/tulane-cmps6730/main/blob/main/lec/parsing/figs/lexicon.png?raw=1)\n",
        "\n",
        "![figs/grammar.png](https://github.com/tulane-cmps6730/main/blob/main/lec/parsing/figs/grammar.png?raw=1)\n",
        "\n",
        "![figs/flight.png](https://github.com/tulane-cmps6730/main/blob/main/lec/parsing/figs/flight.png?raw=1)"
      ],
      "metadata": {
        "id": "5RQ9yQYyHLH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Probabilistic CFGs (PCFGs)"
      ],
      "metadata": {
        "id": "EtfxN_JByzV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "But wait, what about all the ambiguity of language??\n",
        "\n",
        "Recall: **\"I made her duck.\"**\n",
        "\n",
        "Need to model the probabilities of each possible derivation.\n",
        "\n",
        "<br><br>\n",
        "\n",
        "Simple idea: augment each rule in $P$ with a conditional probability:\n",
        "\n",
        "$$ A \\rightarrow \\beta  [p] $$\n",
        "\n",
        "where $p \\triangleq p(A \\rightarrow \\beta \\mid A)$  \n",
        "Probability that nonterminal $A$ is expanded into $\\beta$  \n",
        "Probabilities of all expansions of $A$ must sum to 1.\n",
        "\n",
        "So, a PCFG is a five-tuple $G = (N, \\Sigma, P, S, D)$  \n",
        "where the additional term $D: P \\mapsto \\mathbb{R}$ assigns probabilities to each rule in $P$\n",
        "\n",
        "![pcfg1](https://github.com/tulane-cmps6730/main/blob/main/lec/parsing/figs/pcfg1.png?raw=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pcbdd_DnHZAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Why PCFGs? Resolving ambiguity\n",
        "\n",
        "![ambig](https://github.com/tulane-cmps6730/main/blob/main/lec/parsing/figs/ambig.png?raw=1)"
      ],
      "metadata": {
        "id": "zrsQHnuky3NQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Probability of a parse\n",
        "\n",
        "$$ p(T, S) = \\prod_{n \\in T} p(r(n)) $$\n",
        "- $T$ is a parse\n",
        "- $S$ is a sentence\n",
        "- $r(n)$ is one rule used to expand node $n$ in the parse tree\n",
        "- Probability of a parse is the product of the probabilities of each rule in that parse.\n",
        "\n",
        "Note that\n",
        "$$p(T, S) = p(T)p(S|T) = p(T) $$\n",
        "since $p(S|T) == 1$.\n",
        "\n",
        "E.g., probability of $[S \\rightarrow$ Aux NP VP $ \\wedge $ Aux $\\rightarrow$ can] = .15 * .40\n",
        "\n",
        "<br><br><br>\n",
        "\n",
        "By decomposing the probability into a product of production probabilities, what assumptions have we made?\n",
        "\n",
        "Recall independence assumption $p(A,B) \\triangleq p(A) p(B)$\n",
        "\n",
        "- Each production is independent of all other productions\n",
        "  - E.g., Seeing S $\\rightarrow $NP VP has no impact on NP $\\rightarrow$ Det N\n",
        "- Insensitive to lexical information (words)\n",
        "  - E.g., Seeing NP $\\rightarrow$ Det N is the same whether the noun is \"cat\" or \"people\"\n"
      ],
      "metadata": {
        "id": "Jl-v7RzoIHrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Probability of a sentence\n",
        "\n",
        "$$p(S) = \\sum_{T \\in \\tau(S)} p(T, S) = \\sum_{T \\in \\tau(S)} p(T) $$\n",
        "- $\\tau(S)$ is set of all valid parse trees of sentence S\n",
        "- Probability of a sentence is the sum of the probabilities of all valid parses of that sentence.\n",
        "\n",
        "<br><br>\n",
        "\n",
        "Recall the fluency component of translation models:\n",
        "For a source sentence $A$, find the best target sentence $B$ by:\n",
        "\n",
        "$$T^* \\leftarrow \\mathrm{argmax}_{\\: B} \\: P(B) P(A \\mid B)$$\n",
        "\n",
        "- $P(B)$: \"fluency\". How likely is this sentence $B$ overall? <-- **Can use sentence probability above!**\n",
        "- $P(A \\mid B):$  \"faithfulness\". How closely does the meaning of $B$ match that of $A$?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OvtbMUeDIMFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parsing with PCFGs\n",
        "\n",
        "For a given sentence, we often want to know the highest probability parse:\n",
        "\n",
        "$$\n",
        "T^* = \\mathrm{argmax}_{T \\in \\tau(S)} p(T)\n",
        "$$\n",
        "<br><br><br>\n",
        "\n",
        "**CKY Parsing**\n",
        "\n",
        " Cocke-Younger-Kasami algorithm for finding the most likely parse of a sentence:\n",
        "\n",
        "$$\n",
        "T^* = \\mathrm{argmax}_{T \\in \\tau(S)} p(T)\n",
        "$$\n",
        "\n",
        "- Analogous to the Viterbi algorithm for HMMs, but here extend to parse trees instead of sequences.\n",
        "- CKY is a bottom-up parser using dynamic programming to store intermediate results (for subtrees)\n",
        "- Assumes rules are in **Chomsky Normal Form (CNF)**\n",
        " - Each production is either A $\\rightarrow$ B C or A $\\rightarrow a$.\n",
        " - Any CFG can be converted to CNF (though may expand grammar quadratically)\n",
        "\n",
        "We won't cover this algorithm in detail in this course, but see the textbook for more details (Jurafsky and Martin, Chapter 17)."
      ],
      "metadata": {
        "id": "N2lwNfYhIR4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr size=10 color=#285C4D>\n",
        "\n",
        "## Group Task\n"
      ],
      "metadata": {
        "id": "c0M2CYTNz0pJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIPf7-MF7uNA"
      },
      "source": [
        "Consider again the ice cream example (from [Figure A.2 in Appendix A](https://github.com/tulane-cmps6730/main/blob/main/read/slpA.pdf))\n",
        "\n",
        "  \n",
        "![icecream](https://github.com/tulane-cmps6730/main/blob/main/lec/sequence/figs/icecream.png?raw=1)\n",
        "\n",
        "Apply the Viterbi algorithm to find the most probable path for the input <1,3,1>. In Canvas, enter the most probable path as well as its probability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou2g68Kg7uNA"
      },
      "source": [
        "#### image sources\n",
        "- https://www.cs.colorado.edu/~martin/SLP/\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Mm3ZGl518avu",
        "64OnzvbK9UHl",
        "OQZmpqAf-Cnt",
        "nVD3jy5P-Xne",
        "QtQub9mM-ejU",
        "58uRVDlI-na3",
        "WCpiSJJx-x7J",
        "VgGxOni829EU",
        "gbKWyIly-9DO",
        "uWneomoL_G1Y",
        "xq5e1V_J_Ytf",
        "OhlCYTK5_61_",
        "BUqPhT28EdyM",
        "stLAk3HEyjnk",
        "EtfxN_JByzV_",
        "c0M2CYTNz0pJ"
      ],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}